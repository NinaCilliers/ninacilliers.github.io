<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Predicting brand loyalty | Data Science Portfolio</title>
    <meta name="author" content="Nina  Cilliers">
    <meta name="description" content="An adaptive boosting classifier is optimized to preduct a customer's proclivity to return to Starbucks from survey information.">
    <meta name="keywords" content="nina cilliers, nina gasbarro, data science">


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous">

    <!-- Bootstrap Table -->
    <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.css">

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light">

    

    <!-- Styles -->
    
    <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;">
    
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="https://ninacilliers.github.io/projects/Starbucks_predict/">

    <!-- Dark Mode -->
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark">

    <script src="/assets/js/theme.js"></script>
    <script src="/assets/js/dark_mode.js"></script>
    

  </head>

  <!-- Body -->
  <body class="fixed-top-nav ">

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <a class="navbar-brand title font-weight-lighter" href="/">Data Science Portfolio</a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item ">
                <a class="nav-link" href="/">About</a>
              </li>
              

              <!-- Other pages -->
              <li class="nav-item ">
                <a class="nav-link" href="/projects/">Projects</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/publications/">Publications</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/repositories/">Repositories</a>
              </li>

              <!-- Toogle theme mode -->
              <li class="toggle-container">
                <button id="light-toggle" title="Change theme">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
                </button>
              </li>
            </ul>
          </div>
        </div>
      </nav>

      <!-- Scrolling Progress Bar -->
      <progress id="progress" value="0">
        <div class="progress-container">
          <span class="progress-bar"></span>
        </div>
      </progress>
    </header>


    <!-- Content -->
    <div class="container mt-5">
      
        <!-- page.html -->
        <style>
          img {
            max-width: 100%
          }
        </style>
        <div class="post">

          <article>
            <h1>Predicting brand loyality </h1>
<h4><i>Optimizing an adaptive boosting classifier to preduct return visits to Starbucks</i></h4>
<h4><br></h4>
<h2>Introduction</h2>

<p>A small survey was conducted in Malaysia to learn more about consumer behavior at Starbucks. In sum, a total of 122 individuals answered 20 questions. Questions were asked targeting current purchasing behavior as well as perceptions of Starbucks’ products and facilities. Basic demographic information was also collected. Respondents were asked if they planned on returning to Starbucks in the future, which is taken as an indicator of consumer loyalty.</p>

<p>We extensively explored this data and used clustering techniques to segment the Starbucks’ consumer base in a <a href="link">previous project</a>. Here, a model to predict consumer loyalty was developed. Common classifiers in the Scikit learn package were sampled and optimized. Several classifiers individually reached ~87.5% accuracy on the test dataset. Accuracy was not improved by combining classifiers into a voting classifier.</p>

<p>Finally, feature selection was performed using a random forest classifier. It is shown that customer loyalty is dependent on customers being able to afford Starbucks, perceiving Starbucks as high quality, and enjoying the ambiance. Loyalty prediction using just eight input features performed as well as all individual classifiers built on the full dataset. This indicates that these metrics should be the focus for loyalty improvement and future surveys.</p>

<h2><br></h2>
<h2>Importing data</h2>
<p>Cleaned data is loaded from a <a href="previous">previous project</a>.</p>
<details>
  <summary>Click to show hidden code.</summary>
  <pre>
  import os
  import numpy as np
  import matplotlib.pyplot as plt
  import pandas as pd
  from sklearn import set_config
  import seaborn as sns
  from copy import deepcopy
  from sklearn.preprocessing import OrdinalEncoder
  from sklearn.preprocessing import MinMaxScaler
  #importing packages
  from sklearn.decomposition import PCA 
  from sklearn.cluster import KMeans
  from sklearn.metrics import silhouette_score
  import pickle

  #importaing packages
  from sklearn.model_selection import train_test_split
  from sklearn.tree import DecisionTreeClassifier
  from sklearn.ensemble import RandomForestClassifier
  from sklearn.ensemble import AdaBoostClassifier
  from sklearn.ensemble import ExtraTreesClassifier
  from sklearn.metrics import accuracy_score
  from sklearn.ensemble import GradientBoostingClassifier
  from sklearn.svm import LinearSVC
  from sklearn.svm import SVC
  from sklearn.linear_model import LogisticRegression
  from sklearn.model_selection import RandomizedSearchCV, GridSearchCV
  from scipy.stats import loguniform,expon, uniform, randint
  from sklearn.ensemble import StackingClassifier
  from sklearn.ensemble import VotingClassifier
  </pre>
  <pre>
  #changing settings
  set_config(transform_output="pandas")
  pd.set_option('display.max_columns', 100)
  plt.style.use('ggplot')
  </pre>
</details>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">with</span> <span class="nf">open</span><span class="p">(</span><span class="sh">'</span><span class="s">cleaned_data.pkl</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">wb</span><span class="sh">'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">pickle</span><span class="p">.</span><span class="nf">dump</span><span class="p">(</span><span class="n">df</span><span class="p">,</span><span class="n">f</span><span class="p">)</span>

<span class="n">df</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Age</th>
      <th>Income</th>
      <th>Frequency</th>
      <th>Duration</th>
      <th>Distance</th>
      <th>Price</th>
      <th>Quality rating</th>
      <th>Price rating</th>
      <th>Sale importance</th>
      <th>Ambiance rating</th>
      <th>Wifi rating</th>
      <th>Service rating</th>
      <th>Referral score</th>
      <th>Gender_Male</th>
      <th>Job_Employed</th>
      <th>Job_Housewife</th>
      <th>Job_Self-employed</th>
      <th>Job_Student</th>
      <th>Consumption Location_Dine in</th>
      <th>Consumption Location_Drive-thru</th>
      <th>Consumption Location_Never</th>
      <th>Consumption Location_Take away</th>
      <th>Member_Yes</th>
      <th>Future visits_Yes</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.333333</td>
      <td>0.00</td>
      <td>0.25</td>
      <td>0.25</td>
      <td>0.0</td>
      <td>0.333333</td>
      <td>0.75</td>
      <td>0.50</td>
      <td>1.00</td>
      <td>1.00</td>
      <td>0.75</td>
      <td>0.75</td>
      <td>0.50</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.333333</td>
      <td>0.00</td>
      <td>0.25</td>
      <td>0.00</td>
      <td>0.5</td>
      <td>0.333333</td>
      <td>0.75</td>
      <td>0.50</td>
      <td>0.75</td>
      <td>0.75</td>
      <td>0.75</td>
      <td>1.00</td>
      <td>0.25</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.333333</td>
      <td>0.00</td>
      <td>0.50</td>
      <td>0.25</td>
      <td>1.0</td>
      <td>0.333333</td>
      <td>0.75</td>
      <td>0.50</td>
      <td>0.75</td>
      <td>0.75</td>
      <td>0.75</td>
      <td>0.75</td>
      <td>0.50</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.333333</td>
      <td>0.00</td>
      <td>0.25</td>
      <td>0.00</td>
      <td>1.0</td>
      <td>0.333333</td>
      <td>0.25</td>
      <td>0.00</td>
      <td>0.75</td>
      <td>0.50</td>
      <td>0.50</td>
      <td>0.50</td>
      <td>0.50</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.333333</td>
      <td>0.00</td>
      <td>0.50</td>
      <td>0.25</td>
      <td>0.5</td>
      <td>0.666667</td>
      <td>0.50</td>
      <td>0.50</td>
      <td>0.75</td>
      <td>0.25</td>
      <td>0.25</td>
      <td>0.50</td>
      <td>0.50</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>117</th>
      <td>1.000000</td>
      <td>0.25</td>
      <td>0.50</td>
      <td>0.50</td>
      <td>0.5</td>
      <td>0.666667</td>
      <td>0.50</td>
      <td>0.50</td>
      <td>1.00</td>
      <td>0.50</td>
      <td>0.25</td>
      <td>0.75</td>
      <td>0.75</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>118</th>
      <td>0.333333</td>
      <td>0.00</td>
      <td>0.50</td>
      <td>0.50</td>
      <td>0.5</td>
      <td>1.000000</td>
      <td>1.00</td>
      <td>1.00</td>
      <td>1.00</td>
      <td>1.00</td>
      <td>1.00</td>
      <td>1.00</td>
      <td>1.00</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>119</th>
      <td>0.333333</td>
      <td>0.00</td>
      <td>0.25</td>
      <td>0.25</td>
      <td>0.5</td>
      <td>0.333333</td>
      <td>0.50</td>
      <td>0.25</td>
      <td>0.75</td>
      <td>0.50</td>
      <td>0.50</td>
      <td>0.50</td>
      <td>0.75</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>120</th>
      <td>0.333333</td>
      <td>0.00</td>
      <td>0.25</td>
      <td>0.00</td>
      <td>0.0</td>
      <td>0.333333</td>
      <td>0.75</td>
      <td>0.75</td>
      <td>0.75</td>
      <td>0.75</td>
      <td>0.75</td>
      <td>0.75</td>
      <td>0.75</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>121</th>
      <td>0.333333</td>
      <td>0.50</td>
      <td>0.25</td>
      <td>0.25</td>
      <td>0.5</td>
      <td>0.333333</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>1.00</td>
      <td>0.75</td>
      <td>0.50</td>
      <td>0.50</td>
      <td>0.25</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
  </tbody>
</table>
<p>122 rows × 24 columns</p>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span><span class="p">.</span><span class="nf">info</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;class 'pandas.core.frame.DataFrame'&gt;
RangeIndex: 122 entries, 0 to 121
Data columns (total 24 columns):
 #   Column                           Non-Null Count  Dtype  
---  ------                           --------------  -----  
 0   Age                              122 non-null    float64
 1   Income                           122 non-null    float64
 2   Frequency                        122 non-null    float64
 3   Duration                         122 non-null    float64
 4   Distance                         122 non-null    float64
 5   Price                            122 non-null    float64
 6   Quality rating                   122 non-null    float64
 7   Price rating                     122 non-null    float64
 8   Sale importance                  122 non-null    float64
 9   Ambiance rating                  122 non-null    float64
 10  Wifi rating                      122 non-null    float64
 11  Service rating                   122 non-null    float64
 12  Referral score                   122 non-null    float64
 13  Gender_Male                      122 non-null    float64
 14  Job_Employed                     122 non-null    float64
 15  Job_Housewife                    122 non-null    float64
 16  Job_Self-employed                122 non-null    float64
 17  Job_Student                      122 non-null    float64
 18  Consumption Location_Dine in     122 non-null    float64
 19  Consumption Location_Drive-thru  122 non-null    float64
 20  Consumption Location_Never       122 non-null    float64
 21  Consumption Location_Take away   122 non-null    float64
 22  Member_Yes                       122 non-null    float64
 23  Future visits_Yes                122 non-null    float64
dtypes: float64(24)
memory usage: 23.0 KB
</code></pre></div></div>

<h2><br></h2>
<h2>Feature correlation</h2>
<p>A full EDA and exploration of this data is available in a previous <a href="">project</a>. We present the feature correlation map here, as it guides what we should expect to seee in our model.</p>

<p><img src="/assets/img/starbucks_cluster/output_20_0.png" alt="png"></p>

<ul>
  <li>The tendency to recommend Starbucks as a meeting place, quality rating, ambience rating, service rating, and the desire to visit Starbucks in the future are all positively correlated.</li>
  <li>We also see that items in the consumption location and career categories are negatively correlated, as customers can only select one of these sub-categories.</li>
  <li>Starbucks members tend to have high incomes, visit Starbucks more frequently, spend more money, and positively view Starbucks’ quality.</li>
  <li>Frequent visitors of Starbucks tend to spend more money and positively perceive the product quality.</li>
</ul>

<h2><br></h2>
<h2>Selecting base classifiers</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#Making test and training sets to predict Future visit score
</span><span class="n">X_K</span><span class="p">,</span><span class="n">y</span> <span class="o">=</span> <span class="n">df_unscaled</span><span class="p">.</span><span class="nf">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="sh">'</span><span class="s">Future visits_Yes</span><span class="sh">'</span><span class="p">]),</span> <span class="n">df_unscaled</span><span class="p">[</span><span class="sh">'</span><span class="s">Future visits_Yes</span><span class="sh">'</span><span class="p">]</span>

<span class="n">train_set</span><span class="p">,</span> <span class="n">test_set</span> <span class="o">=</span> <span class="nf">train_test_split</span><span class="p">(</span><span class="n">df_unscaled</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">df_unscaled</span><span class="p">[</span><span class="sh">'</span><span class="s">Future visits_Yes</span><span class="sh">'</span><span class="p">],</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>

<span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span> <span class="o">=</span> <span class="n">train_set</span><span class="p">.</span><span class="nf">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="sh">'</span><span class="s">Future visits_Yes</span><span class="sh">'</span><span class="p">]),</span> <span class="n">train_set</span><span class="p">[</span><span class="sh">'</span><span class="s">Future visits_Yes</span><span class="sh">'</span><span class="p">]</span>
<span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">test_set</span><span class="p">.</span><span class="nf">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="sh">'</span><span class="s">Future visits_Yes</span><span class="sh">'</span><span class="p">]),</span> <span class="n">test_set</span><span class="p">[</span><span class="sh">'</span><span class="s">Future visits_Yes</span><span class="sh">'</span><span class="p">]</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#Sampling selected classifiers
</span><span class="n">rnd_clf</span> <span class="o">=</span> <span class="nc">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">oob_score</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">gboost_clf</span> <span class="o">=</span> <span class="nc">GradientBoostingClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">5000</span><span class="p">,</span> <span class="n">n_iter_no_change</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">learning_rate</span> <span class="o">=</span> <span class="p">.</span><span class="mi">7</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">ada_clf</span> <span class="o">=</span> <span class="nc">AdaBoostClassifier</span><span class="p">(</span><span class="n">n_estimators</span> <span class="o">=</span> <span class="mi">84</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">3.84</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">extra_clf</span> <span class="o">=</span> <span class="nc">ExtraTreesClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">svc_clf</span> <span class="o">=</span> <span class="nc">LinearSVC</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span><span class="n">C</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">1000000</span><span class="p">)</span>
<span class="n">svc_rbf_clf</span> <span class="o">=</span> <span class="nc">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="sh">'</span><span class="s">rbf</span><span class="sh">'</span><span class="p">,</span><span class="n">C</span><span class="o">=</span><span class="mi">18</span><span class="p">,</span><span class="n">gamma</span><span class="o">=</span><span class="p">.</span><span class="mi">0071</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">100000</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span><span class="n">probability</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">log_clf</span> <span class="o">=</span> <span class="nc">LogisticRegression</span><span class="p">(</span><span class="n">C</span><span class="o">=</span><span class="p">.</span><span class="mi">816</span><span class="p">,</span><span class="n">penalty</span><span class="o">=</span><span class="sh">'</span><span class="s">l1</span><span class="sh">'</span><span class="p">,</span><span class="n">solver</span><span class="o">=</span><span class="sh">'</span><span class="s">saga</span><span class="sh">'</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">10000</span><span class="p">)</span>
<span class="c1">#LogisticRegression(C=.734,penalty='l1',solver='saga',random_state=10, max_iter=10000)
</span>
<span class="n">clfs</span> <span class="o">=</span> <span class="p">[</span><span class="n">rnd_clf</span><span class="p">,</span> <span class="n">ada_clf</span><span class="p">,</span> <span class="n">gboost_clf</span><span class="p">,</span> <span class="n">extra_clf</span><span class="p">,</span> <span class="n">svc_clf</span><span class="p">,</span> <span class="n">svc_rbf_clf</span><span class="p">,</span> <span class="n">log_clf</span><span class="p">]</span>

<span class="n">acc</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">classifier</span> <span class="ow">in</span> <span class="n">clfs</span><span class="p">:</span>
  <span class="n">classifier</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
  <span class="n">acc_</span> <span class="o">=</span> <span class="nf">cross_val_score</span><span class="p">(</span><span class="n">classifier</span><span class="p">,</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span><span class="n">scoring</span><span class="o">=</span><span class="sh">'</span><span class="s">accuracy</span><span class="sh">'</span><span class="p">,</span><span class="n">cv</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span><span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">).</span><span class="nf">mean</span><span class="p">()</span>
  <span class="n">acc</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">acc_</span><span class="p">)</span>

<span class="n">names</span> <span class="o">=</span> <span class="p">[</span><span class="sh">'</span><span class="s">Random tree</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Adaptive boosting</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Gradiant boosting</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">Extra trees</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">Linear SVC</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">SVC rbf</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">Logistic regression</span><span class="sh">'</span><span class="p">]</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">barh</span><span class="p">(</span><span class="n">names</span><span class="p">,</span> <span class="n">acc</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">axvline</span><span class="p">(</span><span class="nf">sum</span><span class="p">(</span><span class="n">acc</span><span class="p">)</span><span class="o">/</span><span class="nf">len</span><span class="p">(</span><span class="n">acc</span><span class="p">),</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">k</span><span class="sh">'</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="sh">'</span><span class="s">--</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">'</span><span class="s">Classifier accuracy score</span><span class="sh">'</span><span class="p">);</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">acc</span><span class="p">,</span><span class="n">index</span><span class="o">=</span><span class="n">names</span><span class="p">,</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="sh">'</span><span class="s">Accuracy score (cv=10)</span><span class="sh">'</span><span class="p">]).</span><span class="nf">sort_values</span><span class="p">(</span><span class="sh">'</span><span class="s">Accuracy score (cv=10)</span><span class="sh">'</span><span class="p">,</span><span class="n">ascending</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Accuracy score (cv=10)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Adaptive boosting</th>
      <td>0.875000</td>
    </tr>
    <tr>
      <th>Logistic regression</th>
      <td>0.850000</td>
    </tr>
    <tr>
      <th>Random tree</th>
      <td>0.791667</td>
    </tr>
    <tr>
      <th>Gradiant boosting</th>
      <td>0.791667</td>
    </tr>
    <tr>
      <th>Extra trees</th>
      <td>0.791667</td>
    </tr>
    <tr>
      <th>SVC rbf</th>
      <td>0.725000</td>
    </tr>
    <tr>
      <th>Linear SVC</th>
      <td>0.683333</td>
    </tr>
  </tbody>
</table>
</div>

<h2><br></h2>
<h2>Optimizing base classifiers</h2>
<p>Base clasifiers were optimzed through manual hyperparameter adjustment. The optimized parameters were updated in the above section such that the accuracy scores reflect the optimized model performance.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">iters</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">rs</span> <span class="o">=</span> <span class="mi">10</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#Logistic regression optimization
</span><span class="n">log_best_clf</span> <span class="o">=</span> <span class="nc">LogisticRegression</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">100000</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">rs</span><span class="p">)</span>
<span class="n">lin_params</span> <span class="o">=</span> <span class="p">[{</span>
    <span class="sh">'</span><span class="s">C</span><span class="sh">'</span><span class="p">:</span><span class="nf">uniform</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span><span class="mi">5</span><span class="p">),</span>
    <span class="sh">'</span><span class="s">solver</span><span class="sh">'</span><span class="p">:[</span><span class="sh">'</span><span class="s">saga</span><span class="sh">'</span><span class="p">],</span>
    <span class="sh">'</span><span class="s">penalty</span><span class="sh">'</span><span class="p">:[</span><span class="sh">'</span><span class="s">l1</span><span class="sh">'</span><span class="p">]},{</span>
  <span class="sh">'</span><span class="s">C</span><span class="sh">'</span><span class="p">:</span><span class="nf">uniform</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span><span class="mi">5</span><span class="p">),</span>
   <span class="sh">'</span><span class="s">solver</span><span class="sh">'</span><span class="p">:[</span><span class="sh">'</span><span class="s">saga</span><span class="sh">'</span><span class="p">],</span>
   <span class="sh">'</span><span class="s">penalty</span><span class="sh">'</span><span class="p">:[</span><span class="sh">'</span><span class="s">elasticnet</span><span class="sh">'</span><span class="p">],</span>
   <span class="sh">'</span><span class="s">l1_ratio</span><span class="sh">'</span><span class="p">:</span><span class="nf">uniform</span><span class="p">(.</span><span class="mi">5</span><span class="p">,.</span><span class="mi">9</span><span class="p">)},{</span>   
    <span class="sh">'</span><span class="s">C</span><span class="sh">'</span><span class="p">:</span><span class="nf">uniform</span><span class="p">(.</span><span class="mi">1</span><span class="p">,</span><span class="mi">5</span><span class="p">),</span>
   <span class="sh">'</span><span class="s">solver</span><span class="sh">'</span><span class="p">:[</span><span class="sh">'</span><span class="s">liblinear</span><span class="sh">'</span><span class="p">],</span>
   <span class="sh">'</span><span class="s">penalty</span><span class="sh">'</span><span class="p">:[</span><span class="sh">'</span><span class="s">l2</span><span class="sh">'</span><span class="p">]}</span> 
<span class="p">]</span>

<span class="n">rnd_search</span><span class="o">=</span><span class="nc">RandomizedSearchCV</span><span class="p">(</span><span class="n">log_best_clf</span><span class="p">,</span> <span class="n">param_distributions</span><span class="o">=</span><span class="n">lin_params</span><span class="p">,</span> <span class="n">n_iter</span><span class="o">=</span><span class="n">iters</span><span class="o">*</span><span class="mi">3</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="sh">'</span><span class="s">accuracy</span><span class="sh">'</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="n">rs</span><span class="p">)</span>
<span class="n">rnd_search</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">);</span>
<span class="c1">#Best model
</span><span class="o">%</span><span class="n">log_best_clf</span> <span class="o">=</span> <span class="nc">LogisticRegression</span><span class="p">(</span><span class="n">C</span><span class="o">=</span><span class="p">.</span><span class="mi">816</span><span class="p">,</span><span class="n">penalty</span><span class="o">=</span><span class="sh">'</span><span class="s">l1</span><span class="sh">'</span><span class="p">,</span><span class="n">solver</span><span class="o">=</span><span class="sh">'</span><span class="s">saga</span><span class="sh">'</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">10000</span><span class="p">)</span>
<span class="c1">#best score 0.847
#rnd_search.best_score_, rnd_search.best_params_
</span></code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#Optimizing SVC
</span><span class="n">svc_best_clf</span> <span class="o">=</span><span class="nc">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="sh">'</span><span class="s">rbf</span><span class="sh">'</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">rs</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">10000</span><span class="p">)</span>

<span class="n">svc_params</span> <span class="o">=</span> <span class="p">{</span>
    <span class="sh">'</span><span class="s">C</span><span class="sh">'</span><span class="p">:</span><span class="nf">randint</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span><span class="mi">20</span><span class="p">),</span>
    <span class="sh">'</span><span class="s">gamma</span><span class="sh">'</span><span class="p">:</span><span class="nf">uniform</span><span class="p">(</span><span class="mf">0.001</span><span class="p">,</span><span class="mf">0.05</span><span class="p">)</span>
<span class="p">}</span>

<span class="n">svc_search</span><span class="o">=</span><span class="nc">RandomizedSearchCV</span><span class="p">(</span><span class="n">svc_best_clf</span><span class="p">,</span> <span class="n">param_distributions</span><span class="o">=</span><span class="n">svc_params</span><span class="p">,</span> <span class="n">n_iter</span><span class="o">=</span><span class="n">iters</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="sh">'</span><span class="s">accuracy</span><span class="sh">'</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="n">rs</span><span class="p">)</span>
<span class="n">svc_search</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">);</span>
<span class="c1">#best model 
#svc_best_clf =SVC(kernel='rbf', C=18, gamma=.0071, random_state=10, max_iter=10000)
#best score .844
#svc_search.best_score_, svc_search.best_params_
</span></code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#Optimizing Adaboost
</span><span class="n">ada_best_clf</span> <span class="o">=</span> <span class="nc">AdaBoostClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="n">rs</span><span class="p">)</span>
<span class="n">ada_params</span> <span class="o">=</span> <span class="p">{</span>
   <span class="sh">'</span><span class="s">n_estimators</span><span class="sh">'</span><span class="p">:</span><span class="nf">randint</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">100</span><span class="p">),</span>
   <span class="sh">'</span><span class="s">learning_rate</span><span class="sh">'</span><span class="p">:</span><span class="nf">uniform</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">5</span><span class="p">)}</span>

<span class="n">ada_search</span><span class="o">=</span><span class="nc">RandomizedSearchCV</span><span class="p">(</span><span class="n">ada_best_clf</span><span class="p">,</span> <span class="n">param_distributions</span><span class="o">=</span><span class="n">ada_params</span><span class="p">,</span> <span class="n">n_iter</span><span class="o">=</span><span class="n">iters</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="sh">'</span><span class="s">accuracy</span><span class="sh">'</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">rs</span><span class="p">)</span>
<span class="n">ada_search</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">);</span>

<span class="c1">#best model found 81.5%
#ada_base_best_clf = AdaBoostClassifier(n_estimators = 84, learning_rate=3.84)
#ada_search.best_score_, ada_search.best_params_
</span></code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#Optimizing Adaboost with base estimator 
</span><span class="n">ada_base_best_clf</span> <span class="o">=</span> <span class="nc">AdaBoostClassifier</span><span class="p">(</span><span class="n">estimator</span><span class="o">=</span><span class="nc">DecisionTreeClassifier</span><span class="p">(),</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">ada_params</span> <span class="o">=</span> <span class="p">{</span>
    <span class="sh">'</span><span class="s">estimator__max_features</span><span class="sh">'</span><span class="p">:[</span><span class="sh">'</span><span class="s">sqrt</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">log2</span><span class="sh">'</span><span class="p">],</span>
   <span class="sh">'</span><span class="s">estimator__max_depth</span><span class="sh">'</span><span class="p">:</span><span class="nf">randint</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">20</span><span class="p">),</span>
   <span class="sh">'</span><span class="s">n_estimators</span><span class="sh">'</span><span class="p">:</span><span class="nf">randint</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">200</span><span class="p">),</span>
   <span class="sh">'</span><span class="s">learning_rate</span><span class="sh">'</span><span class="p">:</span><span class="nf">uniform</span><span class="p">(.</span><span class="mi">1</span><span class="p">,</span><span class="mi">50</span><span class="p">),</span>
   <span class="sh">'</span><span class="s">estimator__criterion</span><span class="sh">'</span><span class="p">:</span> <span class="p">[</span><span class="sh">'</span><span class="s">gini</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">entropy</span><span class="sh">'</span><span class="p">],</span>
   <span class="sh">'</span><span class="s">estimator__min_weight_fraction_leaf</span><span class="sh">'</span><span class="p">:</span><span class="nf">uniform</span><span class="p">(.</span><span class="mi">1</span><span class="p">,.</span><span class="mi">5</span><span class="p">)}</span>

<span class="n">ada_search</span><span class="o">=</span><span class="nc">RandomizedSearchCV</span><span class="p">(</span><span class="n">ada_base_best_clf</span><span class="p">,</span> <span class="n">param_distributions</span><span class="o">=</span><span class="n">ada_params</span><span class="p">,</span> <span class="n">n_iter</span><span class="o">=</span><span class="n">iters</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="sh">'</span><span class="s">accuracy</span><span class="sh">'</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">rs</span><span class="p">)</span>
<span class="n">ada_search</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">);</span>

<span class="c1">#best model found 
#ada_base_best_clf = AdaBoostClassifier(estimator=DecisionTreeClassifier(min_weight_fraction_leaf=.11,criterion='entropy', max_depth=17, max_features='sqrt'),n_estimators=108, learning_rate = 25.7, random_state=10)
#best accuracy 89.1%, but performed the same as other adabase model without base estimator optimization on test set at ~84%
#ada_search.best_score_, ada_search.best_params_
</span></code></pre></div></div>

<p>Following previous analyses done on this data set, adaptive boosting was found to be particularly helpful in predicting customer loyalty during cross-validation with accuracy scores &gt;89%, but failed to out-perform on the test set, suggesting over training or sampling issues.</p>

<h2><br></h2>
<h2>Ensemble classifiers</h2>
<h3>Voting classifier</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">voting_clf</span> <span class="o">=</span> <span class="nc">VotingClassifier</span><span class="p">(</span>
    <span class="n">estimators</span><span class="o">=</span><span class="p">[(</span><span class="sh">'</span><span class="s">AdaBoost</span><span class="sh">'</span><span class="p">,</span><span class="n">ada_clf</span><span class="p">),</span>
                <span class="p">(</span><span class="sh">'</span><span class="s">ExtraTrees</span><span class="sh">'</span><span class="p">,</span><span class="n">extra_clf</span><span class="p">),</span>
                <span class="p">(</span><span class="sh">'</span><span class="s">Logistic</span><span class="sh">'</span><span class="p">,</span><span class="n">log_clf</span><span class="p">),</span>
                <span class="p">(</span><span class="sh">'</span><span class="s">GradBoost</span><span class="sh">'</span><span class="p">,</span><span class="n">gboost_clf</span><span class="p">)</span>
                <span class="p">],</span>
                <span class="n">voting</span><span class="o">=</span><span class="sh">'</span><span class="s">hard</span><span class="sh">'</span>

<span class="p">)</span>

<span class="n">voting_clf</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
<span class="n">acc_voting</span> <span class="o">=</span> <span class="nf">cross_val_score</span><span class="p">(</span><span class="n">voting_clf</span><span class="p">,</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span><span class="n">scoring</span><span class="o">=</span><span class="sh">'</span><span class="s">accuracy</span><span class="sh">'</span><span class="p">,</span><span class="n">cv</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span><span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">).</span><span class="nf">mean</span><span class="p">()</span>
<span class="n">acc_voting</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>0.875
</code></pre></div></div>

<h3><br></h3>
<h3>Stacking classifier</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">stacking_clf</span> <span class="o">=</span> <span class="nc">StackingClassifier</span><span class="p">(</span>
    <span class="n">estimators</span><span class="o">=</span><span class="p">[(</span><span class="sh">'</span><span class="s">AdaBoost</span><span class="sh">'</span><span class="p">,</span><span class="n">ada_clf</span><span class="p">),</span>
                <span class="p">(</span><span class="sh">'</span><span class="s">Logistic</span><span class="sh">'</span><span class="p">,</span><span class="n">log_clf</span><span class="p">),</span>
                <span class="p">(</span><span class="sh">'</span><span class="s">GradBoost</span><span class="sh">'</span><span class="p">,</span><span class="n">gboost_clf</span><span class="p">),</span>
                <span class="p">(</span><span class="sh">'</span><span class="s">ExtraTrees</span><span class="sh">'</span><span class="p">,</span><span class="n">extra_clf</span><span class="p">)</span>
                <span class="p">],</span>
                <span class="n">stack_method</span> <span class="o">=</span> <span class="sh">'</span><span class="s">predict_proba</span><span class="sh">'</span>

<span class="p">)</span>

<span class="n">stacking_clf</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
<span class="n">acc_stacking</span> <span class="o">=</span> <span class="nf">cross_val_score</span><span class="p">(</span><span class="n">voting_clf</span><span class="p">,</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span><span class="n">scoring</span><span class="o">=</span><span class="sh">'</span><span class="s">accuracy</span><span class="sh">'</span><span class="p">,</span><span class="n">cv</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span><span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">).</span><span class="nf">mean</span><span class="p">()</span>
<span class="n">acc_stacking</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>0.875
</code></pre></div></div>

<p>We fail to improve upon the accuracy of the adaptive boosting. <b>Thus, the best model for predicting customer loyalty from all the provided features is the adaptive boosting classifier.</b></p>

<h2><br></h2>
<h2>Feature importance</h2>

<p>Key features for predicting consumer loyalty can be used by Starbucks to make improvements. It may also be possible to improve loyalty prediction accuracy.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">rnd_clf</span> <span class="o">=</span> <span class="nc">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">oob_score</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">10</span><span class="p">).</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_K</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">rnd_clf</span><span class="p">.</span><span class="n">oob_score_</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>0.8032786885245902
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">feature_importance</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">Series</span><span class="p">(</span><span class="n">rnd_clf</span><span class="p">.</span><span class="n">feature_importances_</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">rnd_clf</span><span class="p">.</span><span class="n">feature_names_in_</span><span class="p">).</span><span class="nf">sort_values</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</code></pre></div></div>

<details>
  <summary>Click to show hidden code.</summary>
  <pre>
  plt.bar(feature_importance.index.values.tolist(), feature_importance, width=.7,color='lightblue')
  plt.bar(feature_importance[:6].index.values.tolist(), feature_importance[:6], width=.7,color='crimson')
  plt.ylabel('Feature importance', fontsize=14)
  plt.xticks(rotation=90)
  plt.show()
  </pre>
A</details>

<p><img src="/assets/img/starbucks_predict/output_31_0.png" alt="png"></p>

<p>Key features for predicting loyalty include price rating, quality rating, proclivity to recommend Starbucks for a business or social meeting, ambiance rating, and duration of visit.</p>

<h2><br></h2>
<h2>Predicing loyalty using reduced features</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">scores</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">((</span><span class="mi">22</span><span class="p">,</span><span class="nf">len</span><span class="p">(</span><span class="n">names</span><span class="p">))),</span><span class="n">columns</span><span class="o">=</span><span class="n">names</span><span class="p">)</span>
<span class="k">for</span> <span class="n">kk</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">22</span><span class="p">):</span>
  <span class="n">top_features</span> <span class="o">=</span> <span class="n">feature_importance</span><span class="p">[:</span><span class="n">kk</span><span class="p">]</span>
  <span class="n">X_train_top</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">[</span><span class="n">top_features</span><span class="p">.</span><span class="n">index</span><span class="p">.</span><span class="n">values</span><span class="p">.</span><span class="nf">tolist</span><span class="p">()]</span>
  <span class="n">X_test_top</span> <span class="o">=</span> <span class="n">X_test</span><span class="p">[</span><span class="n">top_features</span><span class="p">.</span><span class="n">index</span><span class="p">.</span><span class="n">values</span><span class="p">.</span><span class="nf">tolist</span><span class="p">()]</span>
  <span class="k">for</span> <span class="n">m</span><span class="p">,</span><span class="n">model</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">clfs</span><span class="p">):</span>
    <span class="n">model</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_train_top</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">acc_</span> <span class="o">=</span> <span class="nf">cross_val_score</span><span class="p">(</span><span class="n">model</span><span class="p">,</span><span class="n">X_test_top</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span><span class="n">scoring</span><span class="o">=</span><span class="sh">'</span><span class="s">accuracy</span><span class="sh">'</span><span class="p">,</span><span class="n">cv</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span><span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">).</span><span class="nf">mean</span><span class="p">()</span>
    <span class="n">scores</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">kk</span><span class="p">,</span><span class="n">m</span><span class="p">]</span> <span class="o">=</span> <span class="n">acc_</span>
</code></pre></div></div>

<details>
  <summary>Click to show hidden code.</summary>
  #Plotitng results
  x_range = range(0,22)

  for n,model in enumerate(clfs):
      plt.plot(x_range, scores.iloc[:,n],'o-',label = names[n])
  #lt.plot(x_range, scores['Logistic classifier'],'o-',label = 'Logistic regression', color='lightgreen')
  #plt.plot(x_range, scores['SVC classifier'],'o-',label = 'SVC with rbf kernel', color='pink')
  plt.legend(loc=4,facecolor='white')
  plt.ylabel('Accuracy score')
  plt.xlabel('Features selected')
  plt.show()
</details>

<p><img src="/assets/img/starbucks_predict/output_36_0.png" alt="png"></p>

<p>We see the accuracy score increase as the feature number is increased from 0 to 8. There is no apparent advantage of adding more than 8 features, as the accuracy score is lower or the same from 8-21.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">scores</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Random tree</th>
      <th>Adaptive boosting</th>
      <th>Gradiant boosting</th>
      <th>Extra trees</th>
      <th>Linear SVC</th>
      <th>SVC rbf</th>
      <th>Logistic regression</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.791667</td>
      <td>0.733333</td>
      <td>0.816667</td>
      <td>0.816667</td>
      <td>0.683333</td>
      <td>0.791667</td>
      <td>0.683333</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.716667</td>
      <td>0.733333</td>
      <td>0.741667</td>
      <td>0.741667</td>
      <td>0.825000</td>
      <td>0.766667</td>
      <td>0.766667</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.733333</td>
      <td>0.766667</td>
      <td>0.766667</td>
      <td>0.783333</td>
      <td>0.800000</td>
      <td>0.766667</td>
      <td>0.766667</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.783333</td>
      <td>0.758333</td>
      <td>0.708333</td>
      <td>0.750000</td>
      <td>0.850000</td>
      <td>0.816667</td>
      <td>0.758333</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0.708333</td>
      <td>0.758333</td>
      <td>0.683333</td>
      <td>0.850000</td>
      <td>0.850000</td>
      <td>0.816667</td>
      <td>0.758333</td>
    </tr>
    <tr>
      <th>6</th>
      <td>0.800000</td>
      <td>0.900000</td>
      <td>0.691667</td>
      <td>0.816667</td>
      <td>0.800000</td>
      <td>0.825000</td>
      <td>0.850000</td>
    </tr>
    <tr>
      <th>7</th>
      <td>0.850000</td>
      <td>0.850000</td>
      <td>0.733333</td>
      <td>0.783333</td>
      <td>0.825000</td>
      <td>0.775000</td>
      <td>0.850000</td>
    </tr>
    <tr>
      <th>8</th>
      <td>0.816667</td>
      <td>0.850000</td>
      <td>0.766667</td>
      <td>0.791667</td>
      <td>0.800000</td>
      <td>0.850000</td>
      <td>0.825000</td>
    </tr>
    <tr>
      <th>9</th>
      <td>0.875000</td>
      <td>0.875000</td>
      <td>0.825000</td>
      <td>0.875000</td>
      <td>0.775000</td>
      <td>0.766667</td>
      <td>0.825000</td>
    </tr>
    <tr>
      <th>10</th>
      <td>0.825000</td>
      <td>0.875000</td>
      <td>0.825000</td>
      <td>0.816667</td>
      <td>0.775000</td>
      <td>0.716667</td>
      <td>0.816667</td>
    </tr>
    <tr>
      <th>11</th>
      <td>0.850000</td>
      <td>0.875000</td>
      <td>0.825000</td>
      <td>0.791667</td>
      <td>0.750000</td>
      <td>0.750000</td>
      <td>0.816667</td>
    </tr>
    <tr>
      <th>12</th>
      <td>0.850000</td>
      <td>0.875000</td>
      <td>0.825000</td>
      <td>0.800000</td>
      <td>0.725000</td>
      <td>0.775000</td>
      <td>0.816667</td>
    </tr>
    <tr>
      <th>13</th>
      <td>0.791667</td>
      <td>0.875000</td>
      <td>0.825000</td>
      <td>0.800000</td>
      <td>0.750000</td>
      <td>0.800000</td>
      <td>0.816667</td>
    </tr>
    <tr>
      <th>14</th>
      <td>0.816667</td>
      <td>0.875000</td>
      <td>0.825000</td>
      <td>0.825000</td>
      <td>0.708333</td>
      <td>0.800000</td>
      <td>0.816667</td>
    </tr>
    <tr>
      <th>15</th>
      <td>0.816667</td>
      <td>0.875000</td>
      <td>0.791667</td>
      <td>0.775000</td>
      <td>0.691667</td>
      <td>0.775000</td>
      <td>0.816667</td>
    </tr>
    <tr>
      <th>16</th>
      <td>0.825000</td>
      <td>0.875000</td>
      <td>0.816667</td>
      <td>0.708333</td>
      <td>0.683333</td>
      <td>0.775000</td>
      <td>0.850000</td>
    </tr>
    <tr>
      <th>17</th>
      <td>0.800000</td>
      <td>0.875000</td>
      <td>0.791667</td>
      <td>0.825000</td>
      <td>0.716667</td>
      <td>0.750000</td>
      <td>0.850000</td>
    </tr>
    <tr>
      <th>18</th>
      <td>0.816667</td>
      <td>0.875000</td>
      <td>0.825000</td>
      <td>0.741667</td>
      <td>0.658333</td>
      <td>0.725000</td>
      <td>0.850000</td>
    </tr>
    <tr>
      <th>19</th>
      <td>0.791667</td>
      <td>0.875000</td>
      <td>0.791667</td>
      <td>0.775000</td>
      <td>0.658333</td>
      <td>0.725000</td>
      <td>0.850000</td>
    </tr>
    <tr>
      <th>20</th>
      <td>0.741667</td>
      <td>0.875000</td>
      <td>0.791667</td>
      <td>0.708333</td>
      <td>0.716667</td>
      <td>0.725000</td>
      <td>0.850000</td>
    </tr>
    <tr>
      <th>21</th>
      <td>0.825000</td>
      <td>0.875000</td>
      <td>0.791667</td>
      <td>0.825000</td>
      <td>0.691667</td>
      <td>0.725000</td>
      <td>0.850000</td>
    </tr>
  </tbody>
</table>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">scores</span><span class="p">.</span><span class="nf">max</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Random tree            0.875
Adaptive boosting      0.900
Gradiant boosting      0.825
Extra trees            0.875
Linear SVC             0.850
SVC rbf                0.850
Logistic regression    0.850
dtype: float64
</code></pre></div></div>

<p>We do not see a boost in performance from adding additional features to the model past feature 10. This indicates that future surveys can be brief and only collect this data. There is an increase in performance with the top six features and adaptive boosting. This classifier reaches 90% accuracy on the test set. However, this may be due to the limited number of available samples.</p>

<h2><br></h2>
<h2>Conclusions</h2>

<p>They key predictive features identified in this study indicate that affordability and quality are important factors for returning to Starbucks. The six key features that lead to improved single-classifier prediction of consumer loyalty were as follows:</p>

<ol>
  <li>Positive perception of price options</li>
  <li>Positive perception of product quality</li>
  <li>Recommending Starbucks as a business or social meeting place</li>
  <li>Perception of price</li>
  <li>Rating of ambiance</li>
  <li>Duration of visit</li>
</ol>

<p>To improve the likeliness of future visits to Starbucks, improving perceptions of affordability and ambiance would be the most helpful. All features are not necessary to predict the likeliness. In fact with an additional four features, listed below, the classifiers ae fully functional:</p>

<ol>
  <li>Membership</li>
  <li>Frequency of visit</li>
  <li>Valuing promotions</li>
  <li>Perception of service</li>
</ol>

<p>Collecting more data would enable a more robust statistical treatment of this data. Future surveys should focus on these 10 factors, as other factors were not found to be significant.</p>

          </article>

        </div>
      
    </div>

    <!-- Footer -->    
    <footer class="fixed-bottom">
      <div class="container mt-0">
        © Copyright 2023 Nina  Cilliers. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>.

      </div>
    </footer>

    <!-- JavaScripts -->
    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Masonry & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/assets/js/masonry.js" type="text/javascript"></script>
    
  <!-- Medium Zoom JS -->
  <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script>
  <script defer src="/assets/js/zoom.js"></script>

  <!-- Bootstrap Table -->
  <script defer src="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.js"></script>

  <!-- Load Common JS -->
  <script src="/assets/js/no_defer.js"></script>
  <script defer src="/assets/js/common.js"></script>
  <script defer src="/assets/js/copy_code.js" type="text/javascript"></script>

    
  <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script>
  <script async src="https://badge.dimensions.ai/badge.js"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    
    

<!-- Scrolling Progress Bar -->
<script type="text/javascript">
  /*
   * This JavaScript code has been adapted from the article 
   * https://css-tricks.com/reading-position-indicator/ authored by Pankaj Parashar, 
   * published on the website https://css-tricks.com on the 7th of May, 2014.
   * Couple of changes were made to the original code to make it compatible 
   * with the `al-foio` theme.
   */
  const progressBar = $("#progress");
  /*
   * We set up the bar after all elements are done loading.
   * In some cases, if the images in the page are larger than the intended
   * size they'll have on the page, they'll be resized via CSS to accomodate
   * the desired size. This mistake, however, breaks the computations as the
   * scroll size is computed as soon as the elements finish loading.
   * To account for this, a minimal delay was introduced before computing the
   * values.
   */
  window.onload = function () {
    setTimeout(progressBarSetup, 50);
  };
  /*
   * We set up the bar according to the browser.
   * If the browser supports the progress element we use that.
   * Otherwise, we resize the bar thru CSS styling
   */
  function progressBarSetup() {
    if ("max" in document.createElement("progress")) {
      initializeProgressElement();
      $(document).on("scroll", function() {
        progressBar.attr({ value: getCurrentScrollPosition() });
      });
      $(window).on("resize", initializeProgressElement);
    } else {
      resizeProgressBar();
      $(document).on("scroll", resizeProgressBar);
      $(window).on("resize", resizeProgressBar);
    }
  }
  /*
   * The vertical scroll position is the same as the number of pixels that
   * are hidden from view above the scrollable area. Thus, a value > 0 is
   * how much the user has scrolled from the top
   */
  function getCurrentScrollPosition() {
    return $(window).scrollTop();
  }

  function initializeProgressElement() {
    let navbarHeight = $("#navbar").outerHeight(true);
    $("body").css({ "padding-top": navbarHeight });
    $("progress-container").css({ "padding-top": navbarHeight });
    progressBar.css({ top: navbarHeight });
    progressBar.attr({
      max: getDistanceToScroll(),
      value: getCurrentScrollPosition(),
    });
  }
  /*
   * The offset between the html document height and the browser viewport
   * height will be greater than zero if vertical scroll is possible.
   * This is the distance the user can scroll
   */
  function getDistanceToScroll() {
    return $(document).height() - $(window).height();
  }

  function resizeProgressBar() {
    progressBar.css({ width: getWidthPercentage() + "%" });
  }
  // The scroll ratio equals the percentage to resize the bar
  function getWidthPercentage() {
    return (getCurrentScrollPosition() / getDistanceToScroll()) * 100;
  }
</script>

  </body>
</html>
