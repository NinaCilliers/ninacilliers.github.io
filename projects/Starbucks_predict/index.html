<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Predicting brand loyalty | Nina  Cilliers</title>
    <meta name="author" content="Nina  Cilliers">
    <meta name="description" content="An adaptive boosting classifier is optimized to preduct a customer's proclivity to return to Starbucks from survey information.">
    <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website">


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous">

    <!-- Bootstrap Table -->
    <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.css">

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light">

    

    <!-- Styles -->
    
    <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;">
    
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="https://ninacilliers.github.io/projects/Starbucks_predict/">

    <!-- Dark Mode -->
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark">

    <script src="/assets/js/theme.js"></script>
    <script src="/assets/js/dark_mode.js"></script>
    

  </head>

  <!-- Body -->
  <body class="fixed-top-nav ">

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Nina </span>Cilliers</a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item ">
                <a class="nav-link" href="/">About</a>
              </li>
              

              <!-- Other pages -->
              <li class="nav-item ">
                <a class="nav-link" href="/projects/">Projects</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/publications/">Publications</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/repositories/">Repositories</a>
              </li>

              <!-- Toogle theme mode -->
              <li class="toggle-container">
                <button id="light-toggle" title="Change theme">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
                </button>
              </li>
            </ul>
          </div>
        </div>
      </nav>

      <!-- Scrolling Progress Bar -->
      <progress id="progress" value="0">
        <div class="progress-container">
          <span class="progress-bar"></span>
        </div>
      </progress>
    </header>


    <!-- Content -->
    <div class="container mt-5">
      
        <!-- page.html -->
        <style>
          img {
            max-width: 100%
          }
        </style>
        <div class="post">

          <article>
            <h1>Predicting brand loyality </h1>
<h4><i>Optimizing an adaptive boosting classifier to preduct return visits to Starbucks</i></h4>

<h2>Introduction</h2>

<p>A small survey was conducted in Malaysia to learn more about consumer behavior at Starbucks. In sum, a total of 122 individuals answered 20 questions. Questions were asked targeting current purchasing behavior as well as perceptions of Starbucks’ products and facilities. Basic demographic information was also collected. Respondents were asked if they planned on returning to Starbucks in the future, which is taken as an indicator of consumer loyalty.</p>

<p>We extensively explored this data and used clustering techniques to segment the Starbucks’ consumer base in a {previous project](link). Here, a model to predict consumer loyalty was developed. Common classifiers in the Scikit learn package were sampled and optimized. Several classifiers individually reached ~87.5% accuracy on the test dataset. Accuracy was not improved by combining classifiers into a voting classifier.</p>

<p>Finally, feature selection was performed using a random forest classifier. It is shown that customer loyalty is dependent on customers being able to afford Starbucks, perceiving Starbucks as high quality, and enjoying the ambiance. Loyalty prediction using just eight input features performed as well as all individual classifiers built on the full dataset. This indicates that these metrics should be the focus for loyalty improvement and future surveys.</p>

<h2><br></h2>
<h2>Data cleaning</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#importing packages 
</span><span class="kn">import</span> <span class="n">os</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">from</span> <span class="n">sklearn</span> <span class="kn">import</span> <span class="n">set_config</span>
<span class="kn">import</span> <span class="n">seaborn</span> <span class="k">as</span> <span class="n">sns</span>
<span class="kn">from</span> <span class="n">copy</span> <span class="kn">import</span> <span class="n">deepcopy</span>
<span class="kn">from</span> <span class="n">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">OrdinalEncoder</span>
<span class="kn">from</span> <span class="n">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">MinMaxScaler</span>
<span class="c1">#importing packages
</span><span class="kn">from</span> <span class="n">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">PCA</span> 
<span class="kn">from</span> <span class="n">sklearn.cluster</span> <span class="kn">import</span> <span class="n">KMeans</span>
<span class="kn">from</span> <span class="n">sklearn.metrics</span> <span class="kn">import</span> <span class="n">silhouette_score</span>
<span class="kn">import</span> <span class="n">pickle</span>

<span class="c1">#importaing packages
</span><span class="kn">from</span> <span class="n">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="n">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeClassifier</span>
<span class="kn">from</span> <span class="n">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="kn">from</span> <span class="n">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">AdaBoostClassifier</span>
<span class="kn">from</span> <span class="n">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">ExtraTreesClassifier</span>
<span class="kn">from</span> <span class="n">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>
<span class="kn">from</span> <span class="n">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">GradientBoostingClassifier</span>
<span class="kn">from</span> <span class="n">sklearn.svm</span> <span class="kn">import</span> <span class="n">LinearSVC</span>
<span class="kn">from</span> <span class="n">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVC</span>
<span class="kn">from</span> <span class="n">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span> <span class="n">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">RandomizedSearchCV</span><span class="p">,</span> <span class="n">GridSearchCV</span>
<span class="kn">from</span> <span class="n">scipy.stats</span> <span class="kn">import</span> <span class="n">loguniform</span><span class="p">,</span><span class="n">expon</span><span class="p">,</span> <span class="n">uniform</span><span class="p">,</span> <span class="n">randint</span>
<span class="kn">from</span> <span class="n">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">StackingClassifier</span>
<span class="kn">from</span> <span class="n">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">VotingClassifier</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#changing settings
</span><span class="nf">set_config</span><span class="p">(</span><span class="n">transform_output</span><span class="o">=</span><span class="sh">"</span><span class="s">pandas</span><span class="sh">"</span><span class="p">)</span>
<span class="n">pd</span><span class="p">.</span><span class="nf">set_option</span><span class="p">(</span><span class="sh">'</span><span class="s">display.max_columns</span><span class="sh">'</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">style</span><span class="p">.</span><span class="nf">use</span><span class="p">(</span><span class="sh">'</span><span class="s">ggplot</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">with</span> <span class="nf">open</span><span class="p">(</span><span class="sh">'</span><span class="s">cleaned_data.pkl</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">wb</span><span class="sh">'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">pickle</span><span class="p">.</span><span class="nf">dump</span><span class="p">(</span><span class="n">df</span><span class="p">,</span><span class="n">f</span><span class="p">)</span>

<span class="n">df</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Age</th>
      <th>Income</th>
      <th>Frequency</th>
      <th>Duration</th>
      <th>Distance</th>
      <th>Price</th>
      <th>Quality rating</th>
      <th>Price rating</th>
      <th>Sale importance</th>
      <th>Ambiance rating</th>
      <th>Wifi rating</th>
      <th>Service rating</th>
      <th>Referral score</th>
      <th>Gender_Male</th>
      <th>Job_Employed</th>
      <th>Job_Housewife</th>
      <th>Job_Self-employed</th>
      <th>Job_Student</th>
      <th>Consumption Location_Dine in</th>
      <th>Consumption Location_Drive-thru</th>
      <th>Consumption Location_Never</th>
      <th>Consumption Location_Take away</th>
      <th>Member_Yes</th>
      <th>Future visits_Yes</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.333333</td>
      <td>0.00</td>
      <td>0.25</td>
      <td>0.25</td>
      <td>0.0</td>
      <td>0.333333</td>
      <td>0.75</td>
      <td>0.50</td>
      <td>1.00</td>
      <td>1.00</td>
      <td>0.75</td>
      <td>0.75</td>
      <td>0.50</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.333333</td>
      <td>0.00</td>
      <td>0.25</td>
      <td>0.00</td>
      <td>0.5</td>
      <td>0.333333</td>
      <td>0.75</td>
      <td>0.50</td>
      <td>0.75</td>
      <td>0.75</td>
      <td>0.75</td>
      <td>1.00</td>
      <td>0.25</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.333333</td>
      <td>0.00</td>
      <td>0.50</td>
      <td>0.25</td>
      <td>1.0</td>
      <td>0.333333</td>
      <td>0.75</td>
      <td>0.50</td>
      <td>0.75</td>
      <td>0.75</td>
      <td>0.75</td>
      <td>0.75</td>
      <td>0.50</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.333333</td>
      <td>0.00</td>
      <td>0.25</td>
      <td>0.00</td>
      <td>1.0</td>
      <td>0.333333</td>
      <td>0.25</td>
      <td>0.00</td>
      <td>0.75</td>
      <td>0.50</td>
      <td>0.50</td>
      <td>0.50</td>
      <td>0.50</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.333333</td>
      <td>0.00</td>
      <td>0.50</td>
      <td>0.25</td>
      <td>0.5</td>
      <td>0.666667</td>
      <td>0.50</td>
      <td>0.50</td>
      <td>0.75</td>
      <td>0.25</td>
      <td>0.25</td>
      <td>0.50</td>
      <td>0.50</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>117</th>
      <td>1.000000</td>
      <td>0.25</td>
      <td>0.50</td>
      <td>0.50</td>
      <td>0.5</td>
      <td>0.666667</td>
      <td>0.50</td>
      <td>0.50</td>
      <td>1.00</td>
      <td>0.50</td>
      <td>0.25</td>
      <td>0.75</td>
      <td>0.75</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>118</th>
      <td>0.333333</td>
      <td>0.00</td>
      <td>0.50</td>
      <td>0.50</td>
      <td>0.5</td>
      <td>1.000000</td>
      <td>1.00</td>
      <td>1.00</td>
      <td>1.00</td>
      <td>1.00</td>
      <td>1.00</td>
      <td>1.00</td>
      <td>1.00</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>119</th>
      <td>0.333333</td>
      <td>0.00</td>
      <td>0.25</td>
      <td>0.25</td>
      <td>0.5</td>
      <td>0.333333</td>
      <td>0.50</td>
      <td>0.25</td>
      <td>0.75</td>
      <td>0.50</td>
      <td>0.50</td>
      <td>0.50</td>
      <td>0.75</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>120</th>
      <td>0.333333</td>
      <td>0.00</td>
      <td>0.25</td>
      <td>0.00</td>
      <td>0.0</td>
      <td>0.333333</td>
      <td>0.75</td>
      <td>0.75</td>
      <td>0.75</td>
      <td>0.75</td>
      <td>0.75</td>
      <td>0.75</td>
      <td>0.75</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>121</th>
      <td>0.333333</td>
      <td>0.50</td>
      <td>0.25</td>
      <td>0.25</td>
      <td>0.5</td>
      <td>0.333333</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>1.00</td>
      <td>0.75</td>
      <td>0.50</td>
      <td>0.50</td>
      <td>0.25</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
  </tbody>
</table>
<p>122 rows × 24 columns</p>
</div>

<p>Summary of cleaned dataset:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span><span class="p">.</span><span class="nf">info</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;class 'pandas.core.frame.DataFrame'&gt;
RangeIndex: 122 entries, 0 to 121
Data columns (total 24 columns):
 #   Column                           Non-Null Count  Dtype  
---  ------                           --------------  -----  
 0   Age                              122 non-null    float64
 1   Income                           122 non-null    float64
 2   Frequency                        122 non-null    float64
 3   Duration                         122 non-null    float64
 4   Distance                         122 non-null    float64
 5   Price                            122 non-null    float64
 6   Quality rating                   122 non-null    float64
 7   Price rating                     122 non-null    float64
 8   Sale importance                  122 non-null    float64
 9   Ambiance rating                  122 non-null    float64
 10  Wifi rating                      122 non-null    float64
 11  Service rating                   122 non-null    float64
 12  Referral score                   122 non-null    float64
 13  Gender_Male                      122 non-null    float64
 14  Job_Employed                     122 non-null    float64
 15  Job_Housewife                    122 non-null    float64
 16  Job_Self-employed                122 non-null    float64
 17  Job_Student                      122 non-null    float64
 18  Consumption Location_Dine in     122 non-null    float64
 19  Consumption Location_Drive-thru  122 non-null    float64
 20  Consumption Location_Never       122 non-null    float64
 21  Consumption Location_Take away   122 non-null    float64
 22  Member_Yes                       122 non-null    float64
 23  Future visits_Yes                122 non-null    float64
dtypes: float64(24)
memory usage: 23.0 KB
</code></pre></div></div>

<h2>
<br>&lt;/br&gt;
<h2>Feature correlation</h2>
A full EDA and exploration of this data is available in a previous [project](). We present the feature correlation map here, as it guides what we should expect to seee in our model.

- The tendency to recommend Starbucks as a meeting place, quality rating, ambience rating, service rating, and the desire to visit Starbucks in the future are all positively correlated. 

- We also see that items in the consumption location and career categories are negatively correlated, as customers can only select one of these sub-categories. 

- Starbucks members tend to have high incomes, visit Starbucks more frequently, spend more money, and positively view Starbucks' quality. 

- Frequent visitors of Starbucks tend to spend more money and positively perceive the product quality. 

<h2><br></h2>
<h2>Selecting base classifiers</h2>


```python
from sklearn.model_selection import cross_val_score
```


```python
#Making test and training sets to predict Future visit score
X_K,y = df_unscaled.drop(columns=['Future visits_Yes']), df_unscaled['Future visits_Yes']

train_set, test_set = train_test_split(df_unscaled, test_size=0.3, stratify=df_unscaled['Future visits_Yes'], random_state=10)

X_train, y_train = train_set.drop(columns=['Future visits_Yes']), train_set['Future visits_Yes']
X_test, y_test = test_set.drop(columns=['Future visits_Yes']), test_set['Future visits_Yes']
```


```python
#Sampling selected classifiers
rnd_clf = RandomForestClassifier(n_estimators=50, oob_score=True, random_state=10)
gboost_clf = GradientBoostingClassifier(n_estimators=5000, n_iter_no_change=10, learning_rate = .7, random_state=10)
ada_clf = AdaBoostClassifier(n_estimators = 84, learning_rate=3.84, random_state=10)
extra_clf = ExtraTreesClassifier(n_estimators=15, random_state=10)
svc_clf = LinearSVC(random_state=10,C=100, max_iter=1000000)
svc_rbf_clf = SVC(kernel='rbf',C=18,gamma=.0071, max_iter=100000, random_state = 10,probability=True)
log_clf = LogisticRegression(C=.816,penalty='l1',solver='saga',random_state=10, max_iter=10000)
#LogisticRegression(C=.734,penalty='l1',solver='saga',random_state=10, max_iter=10000)

clfs = [rnd_clf, ada_clf, gboost_clf, extra_clf, svc_clf, svc_rbf_clf, log_clf]

acc = []
for classifier in clfs:
  classifier.fit(X_train, y_train)
  acc_ = cross_val_score(classifier,X_test, y_test,scoring='accuracy',cv=10,n_jobs=-1).mean()
  acc.append(acc_)

names = ['Random tree', 'Adaptive boosting', 'Gradiant boosting','Extra trees','Linear SVC', 'SVC rbf','Logistic regression']

plt.barh(names, acc)
plt.axvline(sum(acc)/len(acc), color='k', linestyle='--')
plt.title('Classifier accuracy score');
plt.show()
```


```python
pd.DataFrame(data=acc,index=names,columns=['Accuracy score (cv=10)']).sort_values('Accuracy score (cv=10)',ascending=False)
```




<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Accuracy score (cv=10)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Adaptive boosting</th>
      <td>0.875000</td>
    </tr>
    <tr>
      <th>Logistic regression</th>
      <td>0.850000</td>
    </tr>
    <tr>
      <th>Random tree</th>
      <td>0.791667</td>
    </tr>
    <tr>
      <th>Gradiant boosting</th>
      <td>0.791667</td>
    </tr>
    <tr>
      <th>Extra trees</th>
      <td>0.791667</td>
    </tr>
    <tr>
      <th>SVC rbf</th>
      <td>0.725000</td>
    </tr>
    <tr>
      <th>Linear SVC</th>
      <td>0.683333</td>
    </tr>
  </tbody>
</table>
</div>



<h2><br></h2>
<h2>Optimizing base classifiers</h2>
Base clasifiers were optimzed through manual hyperparameter adjustment. The optimized parameters were updated in the above section such that the accuracy scores reflect the optimized model performance.


```python
iters = 1
rs = 10
```


```python
#Logistic regression optimization
log_best_clf = LogisticRegression(max_iter=100000, random_state=rs)
lin_params = [{
    'C':uniform(0.1,5),
    'solver':['saga'],
    'penalty':['l1']},{
  'C':uniform(0.1,5),
   'solver':['saga'],
   'penalty':['elasticnet'],
   'l1_ratio':uniform(.5,.9)},{   
    'C':uniform(.1,5),
   'solver':['liblinear'],
   'penalty':['l2']} 
]

rnd_search=RandomizedSearchCV(log_best_clf, param_distributions=lin_params, n_iter=iters*3, cv=10, scoring='accuracy',random_state=rs)
rnd_search.fit(X_train, y_train);
#Best model
%log_best_clf = LogisticRegression(C=.816,penalty='l1',solver='saga',random_state=10, max_iter=10000)
#best score 0.847
#rnd_search.best_score_, rnd_search.best_params_
```


```python
#Optimizing SVC
svc_best_clf =SVC(kernel='rbf', random_state=rs, max_iter=10000)

svc_params = {
    'C':randint(7,20),
    'gamma':uniform(0.001,0.05)
}

svc_search=RandomizedSearchCV(svc_best_clf, param_distributions=svc_params, n_iter=iters, cv=10, scoring='accuracy',random_state=rs)
svc_search.fit(X_train, y_train);
#best model 
#svc_best_clf =SVC(kernel='rbf', C=18, gamma=.0071, random_state=10, max_iter=10000)
#best score .844
#svc_search.best_score_, svc_search.best_params_
```


```python
#Optimizing Adaboost
ada_best_clf = AdaBoostClassifier(random_state=rs)
ada_params = {
   'n_estimators':randint(20,100),
   'learning_rate':uniform(1,5)}

ada_search=RandomizedSearchCV(ada_best_clf, param_distributions=ada_params, n_iter=iters, cv=10, scoring='accuracy', random_state=rs)
ada_search.fit(X_train, y_train);

#best model found 81.5%
#ada_base_best_clf = AdaBoostClassifier(n_estimators = 84, learning_rate=3.84)
#ada_search.best_score_, ada_search.best_params_
```


```python
#Optimizing Adaboost with base estimator 
ada_base_best_clf = AdaBoostClassifier(estimator=DecisionTreeClassifier(), random_state=10)
ada_params = {
    'estimator__max_features':['sqrt', 'log2'],
   'estimator__max_depth':randint(1,20),
   'n_estimators':randint(1,200),
   'learning_rate':uniform(.1,50),
   'estimator__criterion': ['gini', 'entropy'],
   'estimator__min_weight_fraction_leaf':uniform(.1,.5)}

ada_search=RandomizedSearchCV(ada_base_best_clf, param_distributions=ada_params, n_iter=iters, cv=10, scoring='accuracy', random_state=rs)
ada_search.fit(X_train, y_train);

#best model found 
#ada_base_best_clf = AdaBoostClassifier(estimator=DecisionTreeClassifier(min_weight_fraction_leaf=.11,criterion='entropy', max_depth=17, max_features='sqrt'),n_estimators=108, learning_rate = 25.7, random_state=10)
#best accuracy 89.1%, but performed the same as other adabase model without base estimator optimization on test set at ~84%
#ada_search.best_score_, ada_search.best_params_
```

Following previous analyses done on this data set, adaptive boosting was found to be particularly helpful in predicting customer loyalty during cross-validation with accuracy scores &gt;89%, but failed to out-perform on the test set, suggesting over training or sampling issues. 

<h2><br></h2>
<h2>Ensemble classifiers</h2>
<h3>Voting classifier</h3>


```python
voting_clf = VotingClassifier(
    estimators=[('AdaBoost',ada_clf),
                ('ExtraTrees',extra_clf),
                ('Logistic',log_clf),
                ('GradBoost',gboost_clf)
                ],
                voting='hard'

)

voting_clf.fit(X_train,y_train)
acc_voting = cross_val_score(voting_clf,X_test, y_test,scoring='accuracy',cv=10,n_jobs=-1).mean()
acc_voting
```

    c:\Users\corne\anaconda3\lib\site-packages\sklearn\model_selection\_split.py:700: UserWarning: The least populated class in y has only 8 members, which is less than n_splits=10.
      warnings.warn(
    




    0.875



<h3><br></h3>
<h3>Stacking classifier</h3>


```python
stacking_clf = StackingClassifier(
    estimators=[('AdaBoost',ada_clf),
                ('Logistic',log_clf),
                ('GradBoost',gboost_clf),
                ('ExtraTrees',extra_clf)
                ],
                stack_method = 'predict_proba'

)

stacking_clf.fit(X_train,y_train)
acc_stacking = cross_val_score(voting_clf,X_test, y_test,scoring='accuracy',cv=10,n_jobs=-1).mean()
acc_stacking
```

    c:\Users\corne\anaconda3\lib\site-packages\sklearn\model_selection\_split.py:700: UserWarning: The least populated class in y has only 8 members, which is less than n_splits=10.
      warnings.warn(
    




    0.875



We fail to improve upon the accuracy of the adaptive boosting. <b>Thus, the best model for predicting customer loyalty from all the provided features is the adaptive boosting classifier.</b>

<h2><br></h2>
<h2>Feature importance</h2>

Key features for predicting consumer loyalty can be used by Starbucks to make improvements. It may also be possible to improve loyalty prediction accuracy.


```python
rnd_clf = RandomForestClassifier(n_estimators=50, oob_score=True, n_jobs=-1, random_state=10).fit(X_K, y)
rnd_clf.oob_score_
```




    0.8032786885245902




```python
feature_importance = pd.Series(rnd_clf.feature_importances_, index=rnd_clf.feature_names_in_).sort_values(ascending=False)
```


```python
plt.bar(feature_importance.index.values.tolist(), feature_importance, width=.7,color='lightblue')
plt.bar(feature_importance[:6].index.values.tolist(), feature_importance[:6], width=.7,color='crimson')
plt.ylabel('Feature importance', fontsize=14)
plt.xticks(rotation=90)
plt.show()
```


    
![png](output_31_0.png)
    


Key features for predicting loyalty include price rating, quality rating, proclivity to recommend Starbucks for a business or social meeting, ambiance rating, and duration of visit. 



<h2><br></h2>
<h2>Predicing loyalty using reduced features</h2>


```python
#Model definition
'''
ada_top_clf = AdaBoostClassifier(n_estimators=9, learning_rate=4.1, random_state=10)
log_top_clf = LogisticRegression(C=.816,penalty='l1',solver='saga',random_state=10, max_iter=10000)
svc_top_clf =SVC(kernel='rbf', random_state=10, max_iter=10000,C=18, gamma=.0071,probability=True)
'''

#selected_models = [ada_clf, log_clf, svc_clf]
#selected_names = ['Adaptive boosting','Logistic classifier','SVC classifier']

```


```python
#Finding the accuracy score for each feature number
score_ada = []
score_log = []
score_svc = []

scores = pd.DataFrame(data=np.zeros((22,len(names))),columns=names)
for kk in range(1,22):
  top_features = feature_importance[:kk]
  X_train_top = X_train[top_features.index.values.tolist()]
  X_test_top = X_test[top_features.index.values.tolist()]
  for m,model in enumerate(clfs):
    model.fit(X_train_top, y_train)
    acc_ = cross_val_score(model,X_test_top, y_test,scoring='accuracy',cv=10,n_jobs=-1).mean()
    scores.iloc[kk,m] = acc_
```


```python
#Plotitng results
x_range = range(0,22)

for n,model in enumerate(clfs):
    plt.plot(x_range, scores.iloc[:,n],'o-',label = names[n])
#lt.plot(x_range, scores['Logistic classifier'],'o-',label = 'Logistic regression', color='lightgreen')
#plt.plot(x_range, scores['SVC classifier'],'o-',label = 'SVC with rbf kernel', color='pink')
plt.legend(loc=4,facecolor='white')
plt.ylabel('Accuracy score')
plt.xlabel('Features selected')
plt.show()
```


    
![png](output_36_0.png)
    


We see the accuracy score increase as the feature number is increased from 0 to 8. There is no apparent advantage of adding more than 8 features, as the accuracy score is lower or the same from 8-21. 


```python
scores
```




<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Random tree</th>
      <th>Adaptive boosting</th>
      <th>Gradiant boosting</th>
      <th>Extra trees</th>
      <th>Linear SVC</th>
      <th>SVC rbf</th>
      <th>Logistic regression</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.791667</td>
      <td>0.733333</td>
      <td>0.816667</td>
      <td>0.816667</td>
      <td>0.683333</td>
      <td>0.791667</td>
      <td>0.683333</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.716667</td>
      <td>0.733333</td>
      <td>0.741667</td>
      <td>0.741667</td>
      <td>0.825000</td>
      <td>0.766667</td>
      <td>0.766667</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.733333</td>
      <td>0.766667</td>
      <td>0.766667</td>
      <td>0.783333</td>
      <td>0.800000</td>
      <td>0.766667</td>
      <td>0.766667</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.783333</td>
      <td>0.758333</td>
      <td>0.708333</td>
      <td>0.750000</td>
      <td>0.850000</td>
      <td>0.816667</td>
      <td>0.758333</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0.708333</td>
      <td>0.758333</td>
      <td>0.683333</td>
      <td>0.850000</td>
      <td>0.850000</td>
      <td>0.816667</td>
      <td>0.758333</td>
    </tr>
    <tr>
      <th>6</th>
      <td>0.800000</td>
      <td>0.900000</td>
      <td>0.691667</td>
      <td>0.816667</td>
      <td>0.800000</td>
      <td>0.825000</td>
      <td>0.850000</td>
    </tr>
    <tr>
      <th>7</th>
      <td>0.850000</td>
      <td>0.850000</td>
      <td>0.733333</td>
      <td>0.783333</td>
      <td>0.825000</td>
      <td>0.775000</td>
      <td>0.850000</td>
    </tr>
    <tr>
      <th>8</th>
      <td>0.816667</td>
      <td>0.850000</td>
      <td>0.766667</td>
      <td>0.791667</td>
      <td>0.800000</td>
      <td>0.850000</td>
      <td>0.825000</td>
    </tr>
    <tr>
      <th>9</th>
      <td>0.875000</td>
      <td>0.875000</td>
      <td>0.825000</td>
      <td>0.875000</td>
      <td>0.775000</td>
      <td>0.766667</td>
      <td>0.825000</td>
    </tr>
    <tr>
      <th>10</th>
      <td>0.825000</td>
      <td>0.875000</td>
      <td>0.825000</td>
      <td>0.816667</td>
      <td>0.775000</td>
      <td>0.716667</td>
      <td>0.816667</td>
    </tr>
    <tr>
      <th>11</th>
      <td>0.850000</td>
      <td>0.875000</td>
      <td>0.825000</td>
      <td>0.791667</td>
      <td>0.750000</td>
      <td>0.750000</td>
      <td>0.816667</td>
    </tr>
    <tr>
      <th>12</th>
      <td>0.850000</td>
      <td>0.875000</td>
      <td>0.825000</td>
      <td>0.800000</td>
      <td>0.725000</td>
      <td>0.775000</td>
      <td>0.816667</td>
    </tr>
    <tr>
      <th>13</th>
      <td>0.791667</td>
      <td>0.875000</td>
      <td>0.825000</td>
      <td>0.800000</td>
      <td>0.750000</td>
      <td>0.800000</td>
      <td>0.816667</td>
    </tr>
    <tr>
      <th>14</th>
      <td>0.816667</td>
      <td>0.875000</td>
      <td>0.825000</td>
      <td>0.825000</td>
      <td>0.708333</td>
      <td>0.800000</td>
      <td>0.816667</td>
    </tr>
    <tr>
      <th>15</th>
      <td>0.816667</td>
      <td>0.875000</td>
      <td>0.791667</td>
      <td>0.775000</td>
      <td>0.691667</td>
      <td>0.775000</td>
      <td>0.816667</td>
    </tr>
    <tr>
      <th>16</th>
      <td>0.825000</td>
      <td>0.875000</td>
      <td>0.816667</td>
      <td>0.708333</td>
      <td>0.683333</td>
      <td>0.775000</td>
      <td>0.850000</td>
    </tr>
    <tr>
      <th>17</th>
      <td>0.800000</td>
      <td>0.875000</td>
      <td>0.791667</td>
      <td>0.825000</td>
      <td>0.716667</td>
      <td>0.750000</td>
      <td>0.850000</td>
    </tr>
    <tr>
      <th>18</th>
      <td>0.816667</td>
      <td>0.875000</td>
      <td>0.825000</td>
      <td>0.741667</td>
      <td>0.658333</td>
      <td>0.725000</td>
      <td>0.850000</td>
    </tr>
    <tr>
      <th>19</th>
      <td>0.791667</td>
      <td>0.875000</td>
      <td>0.791667</td>
      <td>0.775000</td>
      <td>0.658333</td>
      <td>0.725000</td>
      <td>0.850000</td>
    </tr>
    <tr>
      <th>20</th>
      <td>0.741667</td>
      <td>0.875000</td>
      <td>0.791667</td>
      <td>0.708333</td>
      <td>0.716667</td>
      <td>0.725000</td>
      <td>0.850000</td>
    </tr>
    <tr>
      <th>21</th>
      <td>0.825000</td>
      <td>0.875000</td>
      <td>0.791667</td>
      <td>0.825000</td>
      <td>0.691667</td>
      <td>0.725000</td>
      <td>0.850000</td>
    </tr>
  </tbody>
</table>
</div>




```python
scores.max()
```




    Random tree            0.875
    Adaptive boosting      0.900
    Gradiant boosting      0.825
    Extra trees            0.875
    Linear SVC             0.850
    SVC rbf                0.850
    Logistic regression    0.850
    dtype: float64



We do not see a boost in performance from adding additional features to the model past feature 10. This indicates that future surveys can be brief and only collect this data. There is an increase in performance with the top six features and adaptive boosting. This classifier reaches 90% accuracy on the test set. However, this may be due to the limited number of available samples.



<h2><br></h2>
<h2>Conclusions</h2>

They key predictive features identified in this study indicate that affordability and quality are important factors for returning to Starbucks. The six key features that lead to improved single-classifier prediction of consumer loyalty were as follows: 

1. Positive perception of price options
2. Positive perception of product quality 
3. Recommending Starbucks as a business or social meeting place 
4. Perception of price 
5. Rating of ambiance 
6. Duration of visit 

To improve the likeliness of future visits to Starbucks, improving perceptions of affordability and ambiance would be the most helpful. All features are not necessary to predict the likeliness. In fact with an additional four features, listed below, the classifiers ae fully functional: 

7. Membership 
8. Frequency of visit 
9. Valuing promotions
10. Perception of service 

Collecting more data would enable a more robust statistical treatment of this data. Future surveys should focus on these 10 factors, as other factors were not found to be significant.
</h2>

          </article>

        </div>
      
    </div>

    <!-- Footer -->    
    <footer class="fixed-bottom">
      <div class="container mt-0">
        © Copyright 2023 Nina  Cilliers. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>.

      </div>
    </footer>

    <!-- JavaScripts -->
    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Masonry & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/assets/js/masonry.js" type="text/javascript"></script>
    
  <!-- Medium Zoom JS -->
  <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script>
  <script defer src="/assets/js/zoom.js"></script>

  <!-- Bootstrap Table -->
  <script defer src="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.js"></script>

  <!-- Load Common JS -->
  <script src="/assets/js/no_defer.js"></script>
  <script defer src="/assets/js/common.js"></script>
  <script defer src="/assets/js/copy_code.js" type="text/javascript"></script>

    
  <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script>
  <script async src="https://badge.dimensions.ai/badge.js"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    
    

<!-- Scrolling Progress Bar -->
<script type="text/javascript">
  /*
   * This JavaScript code has been adapted from the article 
   * https://css-tricks.com/reading-position-indicator/ authored by Pankaj Parashar, 
   * published on the website https://css-tricks.com on the 7th of May, 2014.
   * Couple of changes were made to the original code to make it compatible 
   * with the `al-foio` theme.
   */
  const progressBar = $("#progress");
  /*
   * We set up the bar after all elements are done loading.
   * In some cases, if the images in the page are larger than the intended
   * size they'll have on the page, they'll be resized via CSS to accomodate
   * the desired size. This mistake, however, breaks the computations as the
   * scroll size is computed as soon as the elements finish loading.
   * To account for this, a minimal delay was introduced before computing the
   * values.
   */
  window.onload = function () {
    setTimeout(progressBarSetup, 50);
  };
  /*
   * We set up the bar according to the browser.
   * If the browser supports the progress element we use that.
   * Otherwise, we resize the bar thru CSS styling
   */
  function progressBarSetup() {
    if ("max" in document.createElement("progress")) {
      initializeProgressElement();
      $(document).on("scroll", function() {
        progressBar.attr({ value: getCurrentScrollPosition() });
      });
      $(window).on("resize", initializeProgressElement);
    } else {
      resizeProgressBar();
      $(document).on("scroll", resizeProgressBar);
      $(window).on("resize", resizeProgressBar);
    }
  }
  /*
   * The vertical scroll position is the same as the number of pixels that
   * are hidden from view above the scrollable area. Thus, a value > 0 is
   * how much the user has scrolled from the top
   */
  function getCurrentScrollPosition() {
    return $(window).scrollTop();
  }

  function initializeProgressElement() {
    let navbarHeight = $("#navbar").outerHeight(true);
    $("body").css({ "padding-top": navbarHeight });
    $("progress-container").css({ "padding-top": navbarHeight });
    progressBar.css({ top: navbarHeight });
    progressBar.attr({
      max: getDistanceToScroll(),
      value: getCurrentScrollPosition(),
    });
  }
  /*
   * The offset between the html document height and the browser viewport
   * height will be greater than zero if vertical scroll is possible.
   * This is the distance the user can scroll
   */
  function getDistanceToScroll() {
    return $(document).height() - $(window).height();
  }

  function resizeProgressBar() {
    progressBar.css({ width: getWidthPercentage() + "%" });
  }
  // The scroll ratio equals the percentage to resize the bar
  function getWidthPercentage() {
    return (getCurrentScrollPosition() / getDistanceToScroll()) * 100;
  }
</script>

  </body>
</html>
