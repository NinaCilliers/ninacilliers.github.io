<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Painting with convolutional neural networks | Data Science Portfolio</title>
    <meta name="author" content="Nina  Cilliers">
    <meta name="description" content="A novel image is generated with distinct user selected style and content.">
    <meta name="keywords" content="nina cilliers, nina gasbarro, data science">


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous">

    <!-- Bootstrap Table -->
    <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.css">

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light">

    

    <!-- Styles -->
    
    <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;">
    
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="https://ninacilliers.github.io/projects/style_transfer/">

    <!-- Dark Mode -->
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark">

    <script src="/assets/js/theme.js"></script>
    <script src="/assets/js/dark_mode.js"></script>
    

  </head>

  <!-- Body -->
  <body class="fixed-top-nav ">

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <a class="navbar-brand title font-weight-lighter" href="/">Data Science Portfolio</a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item ">
                <a class="nav-link" href="/">About</a>
              </li>
              

              <!-- Other pages -->
              <li class="nav-item ">
                <a class="nav-link" href="/projects/">Projects</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/publications/">Publications</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/repositories/">Repositories</a>
              </li>

              <!-- Toogle theme mode -->
              <li class="toggle-container">
                <button id="light-toggle" title="Change theme">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
                </button>
              </li>
            </ul>
          </div>
        </div>
      </nav>

      <!-- Scrolling Progress Bar -->
      <progress id="progress" value="0">
        <div class="progress-container">
          <span class="progress-bar"></span>
        </div>
      </progress>
    </header>


    <!-- Content -->
    <div class="container mt-5">
      
        <!-- page.html -->
        <style>
          img {
            max-width: 100%
          }
        </style>
        <div class="post">

          <article>
            <h1>Painting with convolutional neural networks</h1>
<h4><i>Using style transfer to generate art with distinct style and content.</i></h4>
<h4><br></h4>
<h2>Introduction</h2>

<p>In this project we generate a new image from two distinct content and style images using a pre-trained VGG neural network. Instead of training the neural network weights, as is typical in a deep learning project, the generated image is adjusted to minimize a custom cost function. This project is inspired by “Deep Learning &amp; Art: Neural Style Transfer” by Andrew Ng and follows the 2015 paper <a href="https://arxiv.org/abs/1508.06576" rel="external nofollow noopener" target="_blank">“A Neural Algorithm of Artistic Style”</a> by Leon Gatys et al.</p>

<p><b>What are content and style in a neural network?</b><br>
Each layer of the VGG neural network produces a differently filtered version of the input image. High levels of a neural network capture objects and their spatial arrangement, while lower levels capture smaller scale features. While it may feel intuitive to use only the lower levels of a neural network to capture style, style is apparent in all scales of artistic representation. Thus, input from all layers is used to represent the style of an image, while input from one higher level layer is used to represent content.</p>

<p>The key idea in “A Neural Algorithm of Artistic Style” is the separation of style and content inputs. The figure below shows the content and style of select layers in a VGG neural network. Style is represented as a gram matrix. <br></p>

<p><img src="/assets/img/style_transfer/intro_fig.png" alt="Overview"><br>
<a href="https://arxiv.org/abs/1508.06576" rel="external nofollow noopener" target="_blank">Gatys et al. 2015</a> 
<br>
<br>
<b> What is a Gram matrix? </b><br>
The Gram matrix has seen wide spread utilization in style representation. The mechanism underlying its utility is thought to be a consequence of minimizing the maximum mean discrepancy between images (See <a href="https://arxiv.org/pdf/1701.01036.pdf" rel="external nofollow noopener" target="_blank">Li et al. 2017</a> for full discussion). The Gram matrix is the product of multiplying a matrix with its own transpose and provides a measure of the degree of feature correlation between the matrix vectors. This transformation results in high values for similar styles and ignores feature position.</p>

<p>F<sup>l</sup><sub>ij</sub> is the activation of the ith filter at position j in layer l. The Gram matrix G<sup>l</sup><sub>ij</sub> is the product of matrix multiplication of the vectorized feature map i and j in each layer l: <br></p>

<p><img src="/assets/img/style_transfer/gram.png" alt="Gram"><br></p>

<h2><br></h2>
<h2>Preparing content image</h2>

<details>
    <summary>Click to show hidden code.</summary>
    <pre>
    import os
    from sklearn.datasets import fetch_openml
    import matplotlib.pyplot as plt
    import keras 
    from PIL import Image
    import copy
    import tensorflow as tf
    import numpy as np
    </pre>
</details>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#import and resize content image
</span></code></pre></div></div>
<details>
    <summary>Click to show hidden code.</summary>
    <pre>
        import 
    #Defining function to look at a digit
    def show_num(input_pic):
    plt.imshow(input_pic,cmap='binary')
    plt.axis(False)

    content_image = Image.open('tokyo.jpg').resize((300,300))
    print(np.array(content_image).shape)
    print('Content Image:')
    content_image
    #[Helena Bradbury](https://www.helenabradbury.com/blog-1/72-hours-in-tokyo-japan)
    </pre>
</details>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Content Image size : 300, 300, 3)
</code></pre></div></div>

<p><img src="/assets/img/style_transfer/output_4_1.png" alt="content image"></p>

<details>
    <summary>Click to show hidden code.</summary>
    <pre>
    #content image formatting 
    print('Content image formatting:')
    print(f'Original size: {content_image.size}')
    </pre>
    <pre>
    #converting to tensor
    content_image = np.array(content_image)/255
    content_image = content_image[None,:,:,:]
    print((f'Tensor size: {content_image.shape}'))
    </pre>
</details>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    Content image formatting:
    Original size: (300, 300)
    Tensor size: (1, 300, 300, 3)
</code></pre></div></div>

<h2><br></h2>
<h2>Style Image</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#import, crop and resize style image
</span></code></pre></div></div>
<details>
    <summary>Click to show hidden code.</summary>
    <pre>
    style_image = Image.open('pablo.jpg')

    print('Style image formatting:')
    print(f'Original size: {style_image.size}')
    </pre>
    <pre>
    #resizing, preserving aspect ratio
    style_image = style_image.resize((300,int(300*818/650)))
    #print(f'Size after resizing: {style_image.size}')
    </pre>
    <pre>
    #cropping
    style_image = style_image.crop((0,10,300,310)) #left, upper, right, lower
    print(f'Size after cropping: {style_image.size}')
    </pre>
    <pre>
    #converting to tensor
    style_image = np.array(style_image)/255
    style_image = style_image[None,:,:,:]
    print((f'Tensor size: {style_image.shape}'))
    </pre>
    &lt;/pre&gt;
</details>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="n">Style</span> <span class="n">image</span> <span class="n">formatting</span><span class="p">:</span>
    <span class="n">Original</span> <span class="n">size</span><span class="p">:</span> <span class="p">(</span><span class="mi">650</span><span class="p">,</span> <span class="mi">818</span><span class="p">)</span>
    <span class="n">Size</span> <span class="n">after</span> <span class="n">cropping</span><span class="p">:</span> <span class="p">(</span><span class="mi">300</span><span class="p">,</span> <span class="mi">300</span><span class="p">)</span>
    <span class="n">Tensor</span> <span class="n">size</span><span class="p">:</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">300</span><span class="p">,</span> <span class="mi">300</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#visualizing adjusted style image 
</span>
<span class="k">def</span> <span class="nf">show_tensor</span><span class="p">(</span><span class="n">tensor</span><span class="p">):</span>
    <span class="n">tensor</span> <span class="o">=</span> <span class="n">tensor</span> <span class="o">*</span> <span class="mi">255</span>
    <span class="n">tensor</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">uint8</span><span class="p">)</span> 
    <span class="k">if</span> <span class="n">np</span><span class="p">.</span><span class="nf">ndim</span><span class="p">(</span><span class="n">tensor</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">3</span><span class="p">:</span>
        <span class="k">assert</span> <span class="n">tensor</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span>
        <span class="n">tensor</span> <span class="o">=</span> <span class="n">tensor</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">Image</span><span class="p">.</span><span class="nf">fromarray</span><span class="p">(</span><span class="n">tensor</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">show_tensor</span><span class="p">(</span><span class="n">style_image</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/assets/img/style_transfer/output_8_0.png" alt="Style image"><br>
<a href="https://www.theguardian.com/artanddesign/2016/may/05/spiritualist-artist-georgiana-houghton-uk-exhibition-courtauld" rel="external nofollow noopener" target="_blank">Portrait of Ambroise Vollard, Pablo Picasso</a></p>

<h2><br></h2>
<h2>Loading VGG-19</h2>

<p>The layers of a pre-trained VGG-19 neural network are used to compute a custom loss function. VGG-19 is a deep convolutional network with 19 convolutional layers. In theory, any trained convolutional neural network could be used for this task. We use VGG-19 and replace the max pooling layers with average pooling layers following <a href="https://arxiv.org/abs/1508.06576" rel="external nofollow noopener" target="_blank">Gatys et al. 2015</a>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">vgg</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">applications</span><span class="p">.</span><span class="nc">VGG19</span><span class="p">(</span><span class="n">include_top</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
                                  <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="n">content_image</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">content_image</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="mi">3</span><span class="p">),</span>
                                  <span class="n">weights</span><span class="o">=</span><span class="sh">'</span><span class="s">imagenet</span><span class="sh">'</span><span class="p">)</span>
<span class="n">vgg</span><span class="p">.</span><span class="n">trainable</span> <span class="o">=</span> <span class="bp">False</span>

<span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="n">vgg</span><span class="p">.</span><span class="n">layers</span><span class="p">:</span>
    <span class="nf">print</span><span class="p">(</span><span class="n">layer</span><span class="p">.</span><span class="n">name</span><span class="p">,</span> <span class="sh">'</span><span class="s">         </span><span class="sh">'</span><span class="p">,</span><span class="n">layer</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>input_28           &lt;keras.engine.input_layer.InputLayer object at 0x000001E1217D0070&gt;
block1_conv1           &lt;keras.layers.convolutional.conv2d.Conv2D object at 0x000001E1217D2350&gt;
block1_conv2           &lt;keras.layers.convolutional.conv2d.Conv2D object at 0x000001E1217D0CA0&gt;
block1_pool           &lt;keras.layers.pooling.max_pooling2d.MaxPooling2D object at 0x000001E1142D4CA0&gt;
block2_conv1           &lt;keras.layers.convolutional.conv2d.Conv2D object at 0x000001E12552F4C0&gt;
block2_conv2           &lt;keras.layers.convolutional.conv2d.Conv2D object at 0x000001E12495C4C0&gt;
block2_pool           &lt;keras.layers.pooling.max_pooling2d.MaxPooling2D object at 0x000001E1217E3250&gt;
block3_conv1           &lt;keras.layers.convolutional.conv2d.Conv2D object at 0x000001E1217D3970&gt;
block3_conv2           &lt;keras.layers.convolutional.conv2d.Conv2D object at 0x000001E126BD1750&gt;
block3_conv3           &lt;keras.layers.convolutional.conv2d.Conv2D object at 0x000001E10959BDF0&gt;
block3_conv4           &lt;keras.layers.convolutional.conv2d.Conv2D object at 0x000001E124C82170&gt;
block3_pool           &lt;keras.layers.pooling.max_pooling2d.MaxPooling2D object at 0x000001E1095991B0&gt;
block4_conv1           &lt;keras.layers.convolutional.conv2d.Conv2D object at 0x000001E1217E1AE0&gt;
block4_conv2           &lt;keras.layers.convolutional.conv2d.Conv2D object at 0x000001E1217E01C0&gt;
block4_conv3           &lt;keras.layers.convolutional.conv2d.Conv2D object at 0x000001E1058E06D0&gt;
block4_conv4           &lt;keras.layers.convolutional.conv2d.Conv2D object at 0x000001E124E1ACE0&gt;
block4_pool           &lt;keras.layers.pooling.max_pooling2d.MaxPooling2D object at 0x000001E109599ED0&gt;
block5_conv1           &lt;keras.layers.convolutional.conv2d.Conv2D object at 0x000001E114605780&gt;
block5_conv2           &lt;keras.layers.convolutional.conv2d.Conv2D object at 0x000001E109598970&gt;
block5_conv3           &lt;keras.layers.convolutional.conv2d.Conv2D object at 0x000001E10E0B5480&gt;
block5_conv4           &lt;keras.layers.convolutional.conv2d.Conv2D object at 0x000001E10E0B75B0&gt;
block5_pool           &lt;keras.layers.pooling.max_pooling2d.MaxPooling2D object at 0x000001E10E0B6D10&gt;
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#switching max pool layers to avg pool layers 
</span>
<span class="c1">#max pool settings
</span><span class="n">poolsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>
<span class="n">padding</span> <span class="o">=</span> <span class="sh">'</span><span class="s">valid</span><span class="sh">'</span>
<span class="n">strides</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>
<span class="n">data_format</span> <span class="o">=</span> <span class="sh">'</span><span class="s">channels_last</span><span class="sh">'</span>


<span class="c1">#finding MaxPool layers and switching to Average Pool
#x = vgg.layers[0].output
</span><span class="nb">input</span> <span class="o">=</span> <span class="n">vgg</span><span class="p">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nb">input</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">vgg</span><span class="p">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">1</span><span class="p">](</span><span class="nb">input</span><span class="p">)</span>
<span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="n">vgg</span><span class="p">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">2</span><span class="p">:]:</span>
    <span class="nf">if </span><span class="p">(</span><span class="nf">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">pooling</span><span class="p">.</span><span class="n">max_pooling2d</span><span class="p">.</span><span class="n">MaxPool2D</span><span class="p">)):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="nc">AveragePooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="n">poolsize</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="n">padding</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="n">strides</span><span class="p">,</span> <span class="n">data_format</span><span class="o">=</span><span class="n">data_format</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
        <span class="c1">#x = tf.keras.layers.AveragePooling2D()(x)
</span>    <span class="k">else</span><span class="p">:</span> <span class="n">x</span> <span class="o">=</span> <span class="nf">layer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">vgg</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="nc">Model</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>

<span class="c1">#checking that this has indeed happened 
</span><span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="n">vgg</span><span class="p">.</span><span class="n">layers</span><span class="p">:</span>
    <span class="nf">print</span><span class="p">(</span><span class="n">layer</span><span class="p">.</span><span class="n">name</span><span class="p">,</span> <span class="sh">'</span><span class="s">         </span><span class="sh">'</span><span class="p">,</span><span class="n">layer</span><span class="p">)</span>

</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>input_28           &lt;keras.engine.input_layer.InputLayer object at 0x000001E1217D0070&gt;
block1_conv1           &lt;keras.layers.convolutional.conv2d.Conv2D object at 0x000001E1217D2350&gt;
block1_conv2           &lt;keras.layers.convolutional.conv2d.Conv2D object at 0x000001E1217D0CA0&gt;
average_pooling2d_76           &lt;keras.layers.pooling.average_pooling2d.AveragePooling2D object at 0x000001E11429B6D0&gt;
block2_conv1           &lt;keras.layers.convolutional.conv2d.Conv2D object at 0x000001E12552F4C0&gt;
block2_conv2           &lt;keras.layers.convolutional.conv2d.Conv2D object at 0x000001E12495C4C0&gt;
average_pooling2d_77           &lt;keras.layers.pooling.average_pooling2d.AveragePooling2D object at 0x000001E10959B340&gt;
block3_conv1           &lt;keras.layers.convolutional.conv2d.Conv2D object at 0x000001E1217D3970&gt;
block3_conv2           &lt;keras.layers.convolutional.conv2d.Conv2D object at 0x000001E126BD1750&gt;
block3_conv3           &lt;keras.layers.convolutional.conv2d.Conv2D object at 0x000001E10959BDF0&gt;
block3_conv4           &lt;keras.layers.convolutional.conv2d.Conv2D object at 0x000001E124C82170&gt;
average_pooling2d_78           &lt;keras.layers.pooling.average_pooling2d.AveragePooling2D object at 0x000001E124A0AE60&gt;
block4_conv1           &lt;keras.layers.convolutional.conv2d.Conv2D object at 0x000001E1217E1AE0&gt;
block4_conv2           &lt;keras.layers.convolutional.conv2d.Conv2D object at 0x000001E1217E01C0&gt;
block4_conv3           &lt;keras.layers.convolutional.conv2d.Conv2D object at 0x000001E1058E06D0&gt;
block4_conv4           &lt;keras.layers.convolutional.conv2d.Conv2D object at 0x000001E124E1ACE0&gt;
average_pooling2d_79           &lt;keras.layers.pooling.average_pooling2d.AveragePooling2D object at 0x000001E1217D32E0&gt;
block5_conv1           &lt;keras.layers.convolutional.conv2d.Conv2D object at 0x000001E114605780&gt;
block5_conv2           &lt;keras.layers.convolutional.conv2d.Conv2D object at 0x000001E109598970&gt;
block5_conv3           &lt;keras.layers.convolutional.conv2d.Conv2D object at 0x000001E10E0B5480&gt;
block5_conv4           &lt;keras.layers.convolutional.conv2d.Conv2D object at 0x000001E10E0B75B0&gt;
average_pooling2d_80           &lt;keras.layers.pooling.average_pooling2d.AveragePooling2D object at 0x000001E1217E1750&gt;
</code></pre></div></div>

<h2><br></h2>
<h2>Cost and loss functions</h2>

<p>Cost functions are built for each style layers and the content layer. These functions are combined into one loss function following <a href="https://arxiv.org/abs/1508.06576" rel="external nofollow noopener" target="_blank">Gatys et al. 2015</a>.<br></p>

<p>The content cost function compares the activation of a single selected layer F<sup>l</sup><sub>ij</sub> to the feature response of the original image P<sup>l</sup><sub>ij</sub>, where the vectors x and p are the generated and original images:</p>

<p><img src="/assets/img/style_transfer/content_loss.png" alt="content cost"><br></p>

<p>The style cost function compares the Gram matrix of a single selected layer G<sup>l</sup><sub>ij</sub> to the Gram matrix of the style image A<sup>l</sup><sub>ij</sub>, where N<sub>i</sub> and M<sub>i</sub> are the number and size of the feature maps. The final style cost function is a weighted sum of each layer’s cost function.</p>

<p><img src="/assets/img/style_transfer/style-cost.png" alt="style cost"><br></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># compute content cost using a_C and a_G
</span><span class="k">def</span> <span class="nf">compute_content_cost</span><span class="p">(</span><span class="n">content_output</span><span class="p">,</span> <span class="n">generated_output</span><span class="p">):</span>
    <span class="n">a_C</span> <span class="o">=</span> <span class="n">content_output</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">a_G</span> <span class="o">=</span> <span class="n">generated_output</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    
    <span class="c1">#a_G dimensions
</span>    <span class="n">_</span><span class="p">,</span> <span class="n">n_H</span><span class="p">,</span> <span class="n">n_W</span><span class="p">,</span> <span class="n">n_C</span> <span class="o">=</span> <span class="n">a_G</span><span class="p">.</span><span class="nf">get_shape</span><span class="p">().</span><span class="nf">as_list</span><span class="p">()</span>
    
    <span class="c1">#reshape
</span>    <span class="n">a_C_unrolled</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">reshape</span><span class="p">(</span><span class="n">a_C</span><span class="p">,</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">[</span><span class="n">_</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_C</span><span class="p">])</span>
    <span class="n">a_G_unrolled</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">reshape</span><span class="p">(</span><span class="n">a_G</span><span class="p">,</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">[</span><span class="n">_</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_C</span><span class="p">])</span>
    
    <span class="c1">#cost 
</span>    <span class="n">J_content</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">reduce_sum</span><span class="p">((</span><span class="n">a_C</span><span class="o">-</span><span class="n">a_G</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="o">/</span><span class="p">(</span><span class="mi">4</span><span class="o">*</span><span class="n">n_H</span><span class="o">*</span><span class="n">n_W</span><span class="o">*</span><span class="n">n_C</span><span class="p">))</span>
    
    <span class="k">return</span> <span class="n">J_content</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">compute_layer_style_cost</span><span class="p">(</span><span class="n">a_S</span><span class="p">,</span> <span class="n">a_G</span><span class="p">):</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">n_H</span><span class="p">,</span> <span class="n">n_W</span><span class="p">,</span> <span class="n">n_C</span> <span class="o">=</span> <span class="n">a_G</span><span class="p">.</span><span class="nf">get_shape</span><span class="p">()</span>
    <span class="n">a_S</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">transpose</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="nf">reshape</span><span class="p">(</span><span class="n">a_S</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="n">n_H</span><span class="o">*</span><span class="n">n_W</span><span class="p">,</span><span class="n">n_C</span><span class="p">]))</span>
    <span class="n">a_G</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">transpose</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="nf">reshape</span><span class="p">(</span><span class="n">a_G</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="n">n_H</span><span class="o">*</span><span class="n">n_W</span><span class="p">,</span><span class="n">n_C</span><span class="p">]))</span>
    
    <span class="n">GS</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">matmul</span><span class="p">(</span><span class="n">a_S</span><span class="p">,</span> <span class="n">tf</span><span class="p">.</span><span class="nf">transpose</span><span class="p">(</span><span class="n">a_S</span><span class="p">))</span>
    <span class="n">GG</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">matmul</span><span class="p">(</span><span class="n">a_G</span><span class="p">,</span> <span class="n">tf</span><span class="p">.</span><span class="nf">transpose</span><span class="p">(</span><span class="n">a_G</span><span class="p">))</span>
    
    <span class="n">J_style_layer</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">reduce_sum</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="nf">square</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="nf">subtract</span><span class="p">(</span><span class="n">GS</span><span class="p">,</span><span class="n">GG</span><span class="p">)))</span><span class="o">/</span><span class="p">(</span><span class="mi">4</span><span class="o">*</span><span class="n">n_C</span><span class="o">**</span><span class="mi">2</span><span class="o">*</span><span class="p">((</span><span class="n">n_H</span><span class="o">*</span><span class="n">n_W</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span>
    
    <span class="k">return</span> <span class="n">J_style_layer</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">compute_style_cost</span><span class="p">(</span><span class="n">style_image_output</span><span class="p">,</span> <span class="n">generated_image_output</span><span class="p">,</span> <span class="n">STYLE_LAYERS</span><span class="o">=</span><span class="n">STYLE_LAYERS</span><span class="p">):</span>
    <span class="n">J_style</span> <span class="o">=</span> <span class="mi">0</span>
    
    <span class="n">a_S</span> <span class="o">=</span> <span class="n">style_image_output</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">a_G</span> <span class="o">=</span> <span class="n">generated_image_output</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">weight</span> <span class="ow">in</span> <span class="nf">zip</span><span class="p">(</span><span class="nf">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">a_S</span><span class="p">)),</span> <span class="n">STYLE_LAYERS</span><span class="p">):</span>  
        <span class="n">J_style_layer</span> <span class="o">=</span> <span class="nf">compute_layer_style_cost</span><span class="p">(</span><span class="n">a_S</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">a_G</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
        <span class="n">J_style</span> <span class="o">+=</span> <span class="n">weight</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">J_style_layer</span>

    <span class="k">return</span> <span class="n">J_style</span>
</code></pre></div></div>

<p>The loss function is a combination of the loss and cost functions, where alpha and beta represent the relative contributions of content and style. In this project we optimize the ratio of alpha to beta. <br></p>

<p><img src="/assets/img/style_transfer/loss-function.png" alt="loss function"><br></p>

<p>We use gradient tape in tensorflow to compute this custom loss function and update the generated image. The weights of the VGG network are unchanged.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">STYLE_LAYERS</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">(</span><span class="sh">'</span><span class="s">block1_conv1</span><span class="sh">'</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">),</span>
    <span class="p">(</span><span class="sh">'</span><span class="s">block2_conv1</span><span class="sh">'</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">),</span>
    <span class="p">(</span><span class="sh">'</span><span class="s">block3_conv1</span><span class="sh">'</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">),</span>
    <span class="p">(</span><span class="sh">'</span><span class="s">block4_conv1</span><span class="sh">'</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">),</span>
    <span class="p">(</span><span class="sh">'</span><span class="s">block5_conv1</span><span class="sh">'</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">)]</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">content_layer</span> <span class="o">=</span> <span class="p">[(</span><span class="sh">'</span><span class="s">block5_conv1</span><span class="sh">'</span><span class="p">,</span> <span class="mi">1</span><span class="p">)]</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">get_layer_outputs</span><span class="p">(</span><span class="n">vgg</span><span class="p">,</span> <span class="n">layer_names</span><span class="p">):</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">vgg</span><span class="p">.</span><span class="nf">get_layer</span><span class="p">(</span><span class="n">layer</span><span class="p">[</span><span class="mi">0</span><span class="p">]).</span><span class="n">output</span> <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="n">layer_names</span><span class="p">]</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="nc">Model</span><span class="p">([</span><span class="n">vgg</span><span class="p">.</span><span class="nb">input</span><span class="p">],</span> <span class="n">outputs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">model</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">vgg_model_outputs</span> <span class="o">=</span> <span class="nf">get_layer_outputs</span><span class="p">(</span><span class="n">vgg</span><span class="p">,</span> <span class="n">STYLE_LAYERS</span> <span class="o">+</span> <span class="n">content_layer</span><span class="p">)</span>

<span class="n">content_target</span> <span class="o">=</span> <span class="nf">vgg_model_outputs</span><span class="p">(</span><span class="n">content_image</span><span class="p">)</span>  <span class="c1"># Content encoder
</span><span class="n">style_targets</span> <span class="o">=</span> <span class="nf">vgg_model_outputs</span><span class="p">(</span><span class="n">style_image</span><span class="p">)</span>     <span class="c1"># Style encoder
</span></code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">preprocessed_content</span> <span class="o">=</span>  <span class="n">tf</span><span class="p">.</span><span class="nc">Variable</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">image</span><span class="p">.</span><span class="nf">convert_image_dtype</span><span class="p">(</span><span class="n">content_image</span><span class="p">,</span> <span class="n">tf</span><span class="p">.</span><span class="n">float32</span><span class="p">))</span>
<span class="n">a_C</span> <span class="o">=</span> <span class="nf">vgg_model_outputs</span><span class="p">(</span><span class="n">preprocessed_content</span><span class="p">)</span>
<span class="n">preprocessed_style</span> <span class="o">=</span>  <span class="n">tf</span><span class="p">.</span><span class="nc">Variable</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">image</span><span class="p">.</span><span class="nf">convert_image_dtype</span><span class="p">(</span><span class="n">style_image</span><span class="p">,</span> <span class="n">tf</span><span class="p">.</span><span class="n">float32</span><span class="p">))</span>
<span class="n">a_S</span> <span class="o">=</span> <span class="nf">vgg_model_outputs</span><span class="p">(</span><span class="n">preprocessed_style</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#alpha_beta is the #ratio of alpha (content) to beta (style)
</span><span class="nd">@tf.function</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">total_cost</span><span class="p">(</span><span class="n">J_content</span><span class="p">,</span> <span class="n">J_style</span><span class="p">,</span> <span class="n">alpha_beta</span><span class="p">):</span>
    <span class="n">J</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">math</span><span class="p">.</span><span class="nf">multiply</span><span class="p">(</span><span class="n">alpha_beta</span><span class="p">,</span><span class="n">J_content</span><span class="p">)</span><span class="o">+</span><span class="n">J_style</span>
    <span class="k">return</span> <span class="n">J</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.01</span>
<span class="n">content_layer</span> <span class="o">=</span> <span class="p">[(</span><span class="sh">'</span><span class="s">block3_conv1</span><span class="sh">'</span><span class="p">,</span> <span class="mi">1</span><span class="p">)]</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">optimizers</span><span class="p">.</span><span class="nc">Adam</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>

<span class="nd">@tf.function</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">train_step</span><span class="p">(</span><span class="n">generated_image</span><span class="p">,</span> <span class="n">alpha_beta</span><span class="p">):</span>

    <span class="k">with</span> <span class="n">tf</span><span class="p">.</span><span class="nc">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">tape</span><span class="p">:</span>
        <span class="n">a_C</span> <span class="o">=</span> <span class="nf">vgg_model_outputs</span><span class="p">(</span><span class="n">preprocessed_content</span><span class="p">)</span>
        <span class="n">a_G</span> <span class="o">=</span> <span class="nf">vgg_model_outputs</span><span class="p">(</span><span class="n">generated_image</span><span class="p">)</span>

        <span class="n">J_style</span> <span class="o">=</span> <span class="nf">compute_style_cost</span><span class="p">(</span><span class="n">a_S</span><span class="p">,</span> <span class="n">a_G</span><span class="p">)</span>
        <span class="n">J_content</span> <span class="o">=</span> <span class="nf">compute_content_cost</span><span class="p">(</span><span class="n">a_C</span><span class="p">,</span> <span class="n">a_G</span><span class="p">)</span>

        <span class="n">J</span> <span class="o">=</span> <span class="nf">total_cost</span><span class="p">(</span><span class="n">J_content</span><span class="p">,</span> <span class="n">J_style</span><span class="p">,</span> <span class="n">alpha_beta</span><span class="p">)</span>
          
    <span class="n">grad</span> <span class="o">=</span> <span class="n">tape</span><span class="p">.</span><span class="nf">gradient</span><span class="p">(</span><span class="n">J</span><span class="p">,</span> <span class="n">generated_image</span><span class="p">)</span>

    <span class="n">optimizer</span><span class="p">.</span><span class="nf">apply_gradients</span><span class="p">([(</span><span class="n">grad</span><span class="p">,</span> <span class="n">generated_image</span><span class="p">)])</span>
    
    <span class="n">generated_image</span><span class="p">.</span><span class="nf">assign</span><span class="p">(</span><span class="nf">clip_me</span><span class="p">(</span><span class="n">generated_image</span><span class="p">))</span>   
    <span class="k">return</span> <span class="n">J</span>
</code></pre></div></div>
<h2><br></h2>
<h2>Initial generated image</h2>
<p>We generate an initial image by adding a low level of noise to our content image.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">clip_me</span><span class="p">(</span><span class="n">image</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">tf</span><span class="p">.</span><span class="nf">clip_by_value</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#initialize image to be geenrated 
#generated_image = tf.Variable(tf.image.convert_image_dtype(content_image, tf.float32))
</span><span class="n">noise</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">uniform</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="nf">shape</span><span class="p">(</span><span class="n">content_image</span><span class="p">),</span><span class="o">-</span><span class="p">.</span><span class="mi">1</span><span class="p">,.</span><span class="mi">1</span><span class="p">)</span>
<span class="n">generated_image</span> <span class="o">=</span> <span class="n">content_image</span> <span class="o">+</span> <span class="n">noise</span>
<span class="n">generated_image</span> <span class="o">=</span> <span class="nf">clip_me</span><span class="p">(</span><span class="n">generated_image</span><span class="p">)</span>
<span class="n">generated_image</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nc">Variable</span><span class="p">(</span><span class="n">generated_image</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">Checking size of generated image: </span><span class="si">{</span><span class="n">generated_image</span><span class="p">.</span><span class="nf">get_shape</span><span class="p">()</span><span class="si">}</span><span class="sh">'</span><span class="p">)</span>

<span class="n">starting_point</span> <span class="o">=</span> <span class="n">copy</span><span class="p">.</span><span class="nf">deepcopy</span><span class="p">(</span><span class="n">generated_image</span><span class="p">)</span>
<span class="n">image_check</span> <span class="o">=</span> <span class="nf">show_tensor</span><span class="p">(</span><span class="n">generated_image</span><span class="p">)</span>
<span class="nf">display</span><span class="p">(</span><span class="n">image_check</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Checking size of generated image: (1, 300, 300, 3)
</code></pre></div></div>

<p><img src="/assets/img/style_transfer/output_26_1.png" alt="initial image"></p>

<h2><br></h2>
<h2>Hyperparameter tunning</h2>
<p>We carefully tune selected hyperparameters to optimize our final generated image: <br><br></p>
<ul>
  <li>Style to cost ratio (alpha to beta)<br>
</li>
  <li>Content layer representation<br>
</li>
  <li>Learning rate <br>
</li>
</ul>

<h3><br></h3>
<h3>Style to cost ratio</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">alpha_beta</span><span class="p">,</span> <span class="n">progress</span><span class="p">):</span>
    <span class="c1">#defines new starting point for each training session
</span>    <span class="c1">#to pick up from last genrated image, comment out
</span>    <span class="n">generated_image</span> <span class="o">=</span> <span class="n">copy</span><span class="p">.</span><span class="nf">deepcopy</span><span class="p">(</span><span class="n">starting_point</span><span class="p">)</span>
    <span class="c1">#display(show_tensor(generated_image))
</span>
    <span class="n">epoch_show</span> <span class="o">=</span> <span class="mi">2</span><span class="o">*</span><span class="nf">int</span><span class="p">(</span><span class="n">epochs</span><span class="o">/</span><span class="mi">10</span><span class="p">)</span>
    <span class="n">img_log</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">epoch_list</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="n">alpha_beta</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">alpha_beta</span><span class="p">,</span><span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">progress</span><span class="p">:</span>
        <span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">Training...</span><span class="sh">'</span><span class="p">)</span>
        
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">epochs</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
        <span class="nf">train_step</span><span class="p">(</span><span class="n">generated_image</span><span class="p">,</span> <span class="n">alpha_beta</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">i</span> <span class="o">%</span> <span class="n">epoch_show</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">progress</span><span class="p">:</span>
                <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">Epoch </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s"> - Done</span><span class="sh">'</span><span class="p">)</span>
            <span class="n">img</span> <span class="o">=</span> <span class="nf">show_tensor</span><span class="p">(</span><span class="n">generated_image</span><span class="p">)</span>
            <span class="c1">#display(img.resize((100,100)))
</span>            <span class="n">img_log</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">generated_image</span><span class="p">)</span>
            <span class="n">epoch_list</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
    
    <span class="k">if</span> <span class="n">progress</span><span class="p">:</span>
        <span class="c1">#display in grid
</span>        <span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">Image training progression:</span><span class="sh">'</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">image</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">img_log</span><span class="p">):</span>
            <span class="n">plt</span><span class="p">.</span><span class="nf">subplot</span><span class="p">(</span><span class="nf">int</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">img_log</span><span class="p">)</span><span class="o">/</span><span class="nf">int</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">img_log</span><span class="p">)</span><span class="o">/</span><span class="mi">2</span><span class="p">)),</span> <span class="nf">int</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">img_log</span><span class="p">)</span><span class="o">/</span><span class="mi">2</span><span class="p">),</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">plt</span><span class="p">.</span><span class="nf">imshow</span><span class="p">(</span><span class="nf">show_tensor</span><span class="p">(</span><span class="n">image</span><span class="p">))</span>
            <span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="nf">str</span><span class="p">(</span><span class="n">epoch_list</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span>
            <span class="n">plt</span><span class="p">.</span><span class="nf">axis</span><span class="p">(</span><span class="sh">'</span><span class="s">off</span><span class="sh">'</span><span class="p">)</span>
        <span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>

    <span class="c1">#return image from last traiing epoch
</span>    <span class="nf">return</span><span class="p">(</span><span class="n">generated_image</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">alpha_beta_range</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="mf">1e-5</span><span class="p">,</span> <span class="mf">1e-4</span><span class="p">,</span> <span class="mf">1e-3</span><span class="p">,</span> <span class="mf">1e-2</span><span class="p">,</span> <span class="p">.</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">10</span><span class="p">],</span><span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">optimizer</span><span class="p">.</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.01</span>
<span class="n">image_log</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">content_layer</span> <span class="o">=</span> <span class="p">[(</span><span class="sh">'</span><span class="s">block5_conv1</span><span class="sh">'</span><span class="p">,</span> <span class="mi">1</span><span class="p">)]</span>

<span class="k">for</span> <span class="n">ratio</span> <span class="ow">in</span> <span class="n">alpha_beta_range</span><span class="p">:</span> 
    <span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">Training alpha to beta ratio</span><span class="sh">'</span><span class="p">,</span><span class="nf">str</span><span class="p">(</span><span class="n">ratio</span><span class="p">),</span><span class="sh">'</span><span class="s">...</span><span class="sh">'</span><span class="p">)</span>  
    <span class="c1">#print('Starting point')
</span>    <span class="c1">#display(show_tensor(starting_point).resize(((100,100))))  
</span>    <span class="n">img</span> <span class="o">=</span> <span class="nf">train</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">ratio</span><span class="p">,</span> <span class="n">progress</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
    <span class="n">image_log</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>

</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Training alpha to beta ratio 1e-05 ...
Training alpha to beta ratio 1e-04 ...
Training alpha to beta ratio 0.001 ...
Training alpha to beta ratio 0.01 ...
Training alpha to beta ratio 0.1 ...
Training alpha to beta ratio 1.0 ...
Training alpha to beta ratio 10.0 ...
</code></pre></div></div>

<details>
    <summary>Click to show hidden code.</summary>
    <pre>
    #results of ratio fit 
    plt.figure(figsize=(10,8))
    rows = int(np.ceil(len(image_log)/2))
    plt.subplot(2,rows,1)
    plt.title('Starting point')
    plt.imshow(show_tensor(starting_point))
    plt.axis('off')

    for i, image in enumerate(image_log):
        plt.subplot(2,rows,i+2)
        plt.title(alpha_beta_range[i])
        plt.imshow(show_tensor(image))
        plt.axis('off')

    plt.tight_layout()
    </pre>
</details>

<p><img src="/assets/img/style_transfer/output_30_0.png" alt="alpha beta"></p>

<p>An alpha to beta ratio of 1 is selected.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">alpha_beta</span> <span class="o">=</span> <span class="mi">1</span>
</code></pre></div></div>
<h3><br></h3>
<h3>Content layer selection</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">CONTENT_LAYERS</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">(</span><span class="sh">'</span><span class="s">block1_conv1</span><span class="sh">'</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
    <span class="p">(</span><span class="sh">'</span><span class="s">block2_conv1</span><span class="sh">'</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
    <span class="p">(</span><span class="sh">'</span><span class="s">block3_conv1</span><span class="sh">'</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
    <span class="p">(</span><span class="sh">'</span><span class="s">block4_conv1</span><span class="sh">'</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
    <span class="p">(</span><span class="sh">'</span><span class="s">block5_conv1</span><span class="sh">'</span><span class="p">,</span> <span class="mi">1</span><span class="p">)]</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">layer_log</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">optimizer</span><span class="p">.</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="p">.</span><span class="mi">01</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">layer</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">CONTENT_LAYERS</span><span class="p">):</span>
    <span class="n">content_layer</span> <span class="o">=</span> <span class="p">[</span><span class="n">CONTENT_LAYERS</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span>
    <span class="n">vgg_model_outputs</span> <span class="o">=</span> <span class="nf">get_layer_outputs</span><span class="p">(</span><span class="n">vgg</span><span class="p">,</span> <span class="n">STYLE_LAYERS</span> <span class="o">+</span> <span class="n">content_layer</span><span class="p">)</span>
    <span class="c1">#print(vgg_model_outputs.outputs[-1])
</span>    <span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">Training</span><span class="sh">'</span><span class="p">,</span><span class="nf">str</span><span class="p">(</span><span class="n">content_layer</span><span class="p">[</span><span class="mi">0</span><span class="p">]).</span><span class="nf">title</span><span class="p">()[</span><span class="mi">2</span><span class="p">:</span><span class="mi">14</span><span class="p">],</span><span class="sh">'</span><span class="s">...</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">img</span> <span class="o">=</span> <span class="nf">train</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">alpha_beta</span><span class="p">,</span> <span class="n">progress</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
    <span class="n">layer_log</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Training Block1_Conv1 ...
Training Block2_Conv1 ...
Training Block3_Conv1 ...
Training Block4_Conv1 ...
Training Block5_Conv1 ...
</code></pre></div></div>

<details>
    <summary>Click to show hidden code.</summary>
    <pre>
    plt.figure(figsize=(10,8))
    plt.subplot(2,int((len(layer_log)+1)/2),1)
    plt.title('Starting point')
    plt.imshow(show_tensor(starting_point))
    plt.axis('off')

    for i, image in enumerate(layer_log):
        plt.subplot(2,int((len(layer_log)+1)/2),i+2)
        plt.title(str(CONTENT_LAYERS[i][0].title()[:6]))
        plt.imshow(show_tensor(image))
        plt.axis('off')

    plt.tight_layout()
    </pre>
</details>

<p><img src="/assets/img/style_transfer/output_36_0.png" alt="content layers"><br></p>

<p>Content layer selection has a subtle effect on the generated image. The highest layer sampled block5_conv1 is used in the spirit of capturing the highest level content features.</p>

<h3><br></h3>
<h3>Learning rate</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">vgg_model_outputs</span> <span class="o">=</span> <span class="nf">get_layer_outputs</span><span class="p">(</span><span class="n">vgg</span><span class="p">,</span> <span class="n">STYLE_LAYERS</span> <span class="o">+</span> <span class="p">[(</span><span class="sh">'</span><span class="s">block5_conv1</span><span class="sh">'</span><span class="p">,</span> <span class="mi">1</span><span class="p">)])</span>
<span class="n">optimizer</span><span class="p">.</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.01</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">lr_log</span> <span class="o">=</span> <span class="p">[]</span>

<span class="n">learning_rates</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.001</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.025</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">]</span>
<span class="k">for</span> <span class="n">rate</span> <span class="ow">in</span> <span class="n">learning_rates</span><span class="p">:</span> 
    <span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">Training</span><span class="sh">'</span><span class="p">,</span><span class="n">rate</span><span class="p">,</span><span class="sh">'</span><span class="s">...</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">optimizer</span><span class="p">.</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="n">rate</span>
    <span class="n">img</span> <span class="o">=</span> <span class="nf">train</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">alpha_beta</span><span class="p">,</span> <span class="n">progress</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
    <span class="n">lr_log</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Training 0.001 ...
Training 0.01 ...
Training 0.025 ...
Training 0.05 ...
Training 0.1 ...
</code></pre></div></div>

<details>
    <summary>Click to show hidden code.</summary>
    <pre>
    #result of learning rate
    plt.figure(figsize=(10,8))
    plt.subplot(2,int((len(lr_log)+1)/2),1)
    plt.title('Starting point')
    plt.imshow(show_tensor(content_image))
    plt.axis('off')

    for i, image in enumerate(lr_log):
        plt.subplot(2,int((len(lr_log)+1)/2),i+2)
        plt.title(learning_rates[i])
        plt.imshow(show_tensor(image))
        plt.axis('off')

    plt.tight_layout()
    </pre>
</details>

<p><img src="/assets/img/style_transfer/output_40_0.png" alt="learning rates"><br></p>

<p>Images generated with learning rates of 0.01 and 0.025 have the desirable combination of visable changes to style and clearly discernable buildings. We select 0.01 for use in our final image generation.</p>

<h2><br></h2>
<h2>Final image generation</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">optimizer</span><span class="p">.</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.01</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">1000</span>

<span class="n">img</span> <span class="o">=</span> <span class="nf">train</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">alpha_beta</span><span class="p">,</span> <span class="n">progress</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Training...
Epoch 0 - Done
Epoch 200 - Done
Epoch 400 - Done
Epoch 600 - Done
Epoch 800 - Done
Epoch 1000 - Done   
</code></pre></div></div>

<details>
    <summary>Click to show hidden code.</summary>
    <pre>
    plt.figure(figsize=(10,8))
    plt.subplot(1,3,1)
    plt.imshow(show_tensor(content_image))
    plt.axis('off')
    plt.title('Content Image')

    plt.subplot(1,3,2)
    plt.imshow(show_tensor(style_image))
    plt.axis('off')
    plt.title('Style Image')

    plt.subplot(1,3,3)
    plt.imshow(show_tensor(img))
    plt.axis('off')
    plt.title('Generated image')

    plt.tight_layout()
    </pre>
</details>

<p><img src="/assets/img/style_transfer/output_44_0.png" alt="final image generation"></p>


          </article>

        </div>
      
    </div>

    <!-- Footer -->    
    <footer class="fixed-bottom">
      <div class="container mt-0">
        © Copyright 2023 Nina  Cilliers. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>.

      </div>
    </footer>

    <!-- JavaScripts -->
    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Masonry & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/assets/js/masonry.js" type="text/javascript"></script>
    
  <!-- Medium Zoom JS -->
  <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script>
  <script defer src="/assets/js/zoom.js"></script>

  <!-- Bootstrap Table -->
  <script defer src="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.js"></script>

  <!-- Load Common JS -->
  <script src="/assets/js/no_defer.js"></script>
  <script defer src="/assets/js/common.js"></script>
  <script defer src="/assets/js/copy_code.js" type="text/javascript"></script>

    
  <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script>
  <script async src="https://badge.dimensions.ai/badge.js"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    
    

<!-- Scrolling Progress Bar -->
<script type="text/javascript">
  /*
   * This JavaScript code has been adapted from the article 
   * https://css-tricks.com/reading-position-indicator/ authored by Pankaj Parashar, 
   * published on the website https://css-tricks.com on the 7th of May, 2014.
   * Couple of changes were made to the original code to make it compatible 
   * with the `al-foio` theme.
   */
  const progressBar = $("#progress");
  /*
   * We set up the bar after all elements are done loading.
   * In some cases, if the images in the page are larger than the intended
   * size they'll have on the page, they'll be resized via CSS to accomodate
   * the desired size. This mistake, however, breaks the computations as the
   * scroll size is computed as soon as the elements finish loading.
   * To account for this, a minimal delay was introduced before computing the
   * values.
   */
  window.onload = function () {
    setTimeout(progressBarSetup, 50);
  };
  /*
   * We set up the bar according to the browser.
   * If the browser supports the progress element we use that.
   * Otherwise, we resize the bar thru CSS styling
   */
  function progressBarSetup() {
    if ("max" in document.createElement("progress")) {
      initializeProgressElement();
      $(document).on("scroll", function() {
        progressBar.attr({ value: getCurrentScrollPosition() });
      });
      $(window).on("resize", initializeProgressElement);
    } else {
      resizeProgressBar();
      $(document).on("scroll", resizeProgressBar);
      $(window).on("resize", resizeProgressBar);
    }
  }
  /*
   * The vertical scroll position is the same as the number of pixels that
   * are hidden from view above the scrollable area. Thus, a value > 0 is
   * how much the user has scrolled from the top
   */
  function getCurrentScrollPosition() {
    return $(window).scrollTop();
  }

  function initializeProgressElement() {
    let navbarHeight = $("#navbar").outerHeight(true);
    $("body").css({ "padding-top": navbarHeight });
    $("progress-container").css({ "padding-top": navbarHeight });
    progressBar.css({ top: navbarHeight });
    progressBar.attr({
      max: getDistanceToScroll(),
      value: getCurrentScrollPosition(),
    });
  }
  /*
   * The offset between the html document height and the browser viewport
   * height will be greater than zero if vertical scroll is possible.
   * This is the distance the user can scroll
   */
  function getDistanceToScroll() {
    return $(document).height() - $(window).height();
  }

  function resizeProgressBar() {
    progressBar.css({ width: getWidthPercentage() + "%" });
  }
  // The scroll ratio equals the percentage to resize the bar
  function getWidthPercentage() {
    return (getCurrentScrollPosition() / getDistanceToScroll()) * 100;
  }
</script>

  </body>
</html>
